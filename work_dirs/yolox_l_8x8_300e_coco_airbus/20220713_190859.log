2022-07-13 19:08:59,169 - mmdet - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.10 (default, Nov 26 2021, 20:14:08) [GCC 9.3.0]
CUDA available: True
GPU 0: NVIDIA GeForce RTX 3090
CUDA_HOME: /usr
NVCC: Cuda compilation tools, release 10.1, V10.1.24
GCC: x86_64-linux-gnu-gcc (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0
PyTorch: 1.11.0+cu113
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.5.2 (Git Hash a9302535553c73243c632ad3c4c80beec3d19a1e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.11.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

TorchVision: 0.12.0+cu113
OpenCV: 4.6.0
MMCV: 1.5.0
MMCV Compiler: GCC 7.3
MMCV CUDA Compiler: 11.3
MMDetection: 2.22.0+8f28e2f
------------------------------------------------------------

2022-07-13 19:08:59,897 - mmdet - INFO - Distributed training: False
2022-07-13 19:09:00,619 - mmdet - INFO - Config:
optimizer = dict(
    type='SGD',
    lr=0.01,
    momentum=0.9,
    weight_decay=0.0005,
    nesterov=True,
    paramwise_cfg=dict(norm_decay_mult=0.0, bias_decay_mult=0.0))
optimizer_config = dict(grad_clip=None)
lr_config = dict(
    policy='YOLOX',
    warmup='exp',
    by_epoch=False,
    warmup_by_epoch=True,
    warmup_ratio=1,
    warmup_iters=5,
    num_last_epochs=15,
    min_lr_ratio=0.05)
runner = dict(type='EpochBasedRunner', max_epochs=300)
checkpoint_config = dict(interval=10)
log_config = dict(
    interval=10,
    hooks=[dict(type='TextLoggerHook'),
           dict(type='TensorboardLoggerHook')])
custom_hooks = [
    dict(type='YOLOXModeSwitchHook', num_last_epochs=15, priority=48),
    dict(type='SyncNormHook', num_last_epochs=15, interval=10, priority=48),
    dict(
        type='ExpMomentumEMAHook',
        resume_from=None,
        momentum=0.0001,
        priority=49)
]
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = '/home/naama/Documents/MyProjects/ml_projects/ml_detection/ml_detection/work_dirs/yolox_l_8x8_300e_coco_airbus/epoch_280.pth'
workflow = [('train', 1)]
opencv_num_threads = 0
mp_start_method = 'fork'
img_scale = (640, 640)
model = dict(
    type='YOLOX',
    input_size=(640, 640),
    random_size_range=(15, 25),
    random_size_interval=10,
    backbone=dict(type='CSPDarknet', deepen_factor=1.0, widen_factor=1.0),
    neck=dict(
        type='YOLOXPAFPN',
        in_channels=[256, 512, 1024],
        out_channels=256,
        num_csp_blocks=3),
    bbox_head=dict(
        type='YOLOXHead', num_classes=1, in_channels=256, feat_channels=256),
    train_cfg=dict(assigner=dict(type='SimOTAAssigner', center_radius=2.5)),
    test_cfg=dict(score_thr=0.01, nms=dict(type='nms', iou_threshold=0.65)))
data_root = '/home/naama/Data/autoML_datasets/airbus_aircraft_sliced_coco'
dataset_type = 'CocoDataset'
train_pipeline = [
    dict(type='Mosaic', img_scale=(640, 640), pad_val=114.0),
    dict(
        type='RandomAffine', scaling_ratio_range=(0.1, 2),
        border=(-320, -320)),
    dict(
        type='MixUp',
        img_scale=(640, 640),
        ratio_range=(0.8, 1.6),
        pad_val=114.0),
    dict(type='YOLOXHSVRandomAug'),
    dict(type='RandomFlip', flip_ratio=0.5),
    dict(type='Resize', img_scale=(640, 640), keep_ratio=True),
    dict(
        type='Normalize',
        mean=[135.62, 133.61, 118.17],
        std=[52.2, 47.8, 46.4],
        to_rgb=True),
    dict(
        type='Pad',
        pad_to_square=True,
        pad_val=dict(img=(114.0, 114.0, 114.0))),
    dict(type='FilterAnnotations', min_gt_bbox_wh=(1, 1), keep_empty=False),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])
]
train_dataset = dict(
    type='MultiImageMixDataset',
    dataset=dict(
        type='CocoDataset',
        ann_file=
        '/home/naama/Data/autoML_datasets/airbus_aircraft_sliced_coco/train/sliced_bbox_coco.json',
        img_prefix=
        '/home/naama/Data/autoML_datasets/airbus_aircraft_sliced_coco/train/sliced_images/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations', with_bbox=True),
            dict(type='RandomCrop', crop_size=(640, 640))
        ],
        filter_empty_gt=False,
        classes=('Airplane', )),
    pipeline=[
        dict(type='Mosaic', img_scale=(640, 640), pad_val=114.0),
        dict(
            type='RandomAffine',
            scaling_ratio_range=(0.1, 2),
            border=(-320, -320)),
        dict(
            type='MixUp',
            img_scale=(640, 640),
            ratio_range=(0.8, 1.6),
            pad_val=114.0),
        dict(type='YOLOXHSVRandomAug'),
        dict(type='RandomFlip', flip_ratio=0.5),
        dict(type='Resize', img_scale=(640, 640), keep_ratio=True),
        dict(
            type='Normalize',
            mean=[135.62, 133.61, 118.17],
            std=[52.2, 47.8, 46.4],
            to_rgb=True),
        dict(
            type='Pad',
            pad_to_square=True,
            pad_val=dict(img=(114.0, 114.0, 114.0))),
        dict(
            type='FilterAnnotations', min_gt_bbox_wh=(1, 1), keep_empty=False),
        dict(type='DefaultFormatBundle'),
        dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])
    ])
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(640, 640),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[135.62, 133.61, 118.17],
                std=[52.2, 47.8, 46.4],
                to_rgb=True),
            dict(
                type='Pad',
                pad_to_square=True,
                pad_val=dict(img=(114.0, 114.0, 114.0))),
            dict(type='DefaultFormatBundle'),
            dict(type='Collect', keys=['img'])
        ])
]
data = dict(
    samples_per_gpu=8,
    workers_per_gpu=4,
    persistent_workers=True,
    train=dict(
        type='MultiImageMixDataset',
        dataset=dict(
            type='CocoDataset',
            ann_file=
            '/home/naama/Data/autoML_datasets/airbus_aircraft_sliced_coco/train/sliced_bbox_coco.json',
            img_prefix=
            '/home/naama/Data/autoML_datasets/airbus_aircraft_sliced_coco/train/sliced_images/',
            pipeline=[
                dict(type='LoadImageFromFile'),
                dict(type='LoadAnnotations', with_bbox=True),
                dict(type='RandomCrop', crop_size=(640, 640))
            ],
            filter_empty_gt=False,
            classes=('Airplane', )),
        pipeline=[
            dict(type='Mosaic', img_scale=(640, 640), pad_val=114.0),
            dict(
                type='RandomAffine',
                scaling_ratio_range=(0.1, 2),
                border=(-320, -320)),
            dict(
                type='MixUp',
                img_scale=(640, 640),
                ratio_range=(0.8, 1.6),
                pad_val=114.0),
            dict(type='YOLOXHSVRandomAug'),
            dict(type='RandomFlip', flip_ratio=0.5),
            dict(type='Resize', img_scale=(640, 640), keep_ratio=True),
            dict(
                type='Normalize',
                mean=[135.62, 133.61, 118.17],
                std=[52.2, 47.8, 46.4],
                to_rgb=True),
            dict(
                type='Pad',
                pad_to_square=True,
                pad_val=dict(img=(114.0, 114.0, 114.0))),
            dict(
                type='FilterAnnotations',
                min_gt_bbox_wh=(1, 1),
                keep_empty=False),
            dict(type='DefaultFormatBundle'),
            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])
        ]),
    val=dict(
        type='CocoDataset',
        ann_file=
        '/home/naama/Data/autoML_datasets/airbus_aircraft_sliced_coco/test/sliced_bbox_coco.json',
        img_prefix=
        '/home/naama/Data/autoML_datasets/airbus_aircraft_sliced_coco/test/sliced_images/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(640, 640),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[135.62, 133.61, 118.17],
                        std=[52.2, 47.8, 46.4],
                        to_rgb=True),
                    dict(
                        type='Pad',
                        pad_to_square=True,
                        pad_val=dict(img=(114.0, 114.0, 114.0))),
                    dict(type='DefaultFormatBundle'),
                    dict(type='Collect', keys=['img'])
                ])
        ],
        classes=('Airplane', )),
    test=dict(
        type='CocoDataset',
        ann_file=
        '/home/naama/Data/autoML_datasets/airbus_aircraft_sliced_coco/test/sliced_bbox_coco.json',
        img_prefix=
        '/home/naama/Data/autoML_datasets/airbus_aircraft_sliced_coco/test/sliced_images/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(640, 640),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[135.62, 133.61, 118.17],
                        std=[52.2, 47.8, 46.4],
                        to_rgb=True),
                    dict(
                        type='Pad',
                        pad_to_square=True,
                        pad_val=dict(img=(114.0, 114.0, 114.0))),
                    dict(type='DefaultFormatBundle'),
                    dict(type='Collect', keys=['img'])
                ])
        ],
        classes=('Airplane', )))
max_epochs = 300
num_last_epochs = 15
interval = 10
evaluation = dict(
    save_best='auto', interval=10, dynamic_intervals=[(285, 1)], metric='bbox')
mmdetection_path = '/home/naama/Documents/MyProjects/ml_projects/mmdetection'
dataset_path = '/home/naama/Data/autoML_datasets/airbus_aircraft_sliced_coco'
load_pth_path = 'https://download.openmmlab.com/mmdetection/v2.0/yolox/yolox_l_8x8_300e_coco/yolox_l_8x8_300e_coco_20211126_140236-d3bd2b23.pth'
classes = ('Airplane', )
img_norm_cfg = dict(
    mean=[135.62, 133.61, 118.17], std=[52.2, 47.8, 46.4], to_rgb=True)
work_dir = './work_dirs/yolox_l_8x8_300e_coco_airbus'
auto_resume = False
gpu_ids = [0]

2022-07-13 19:09:00,620 - mmdet - INFO - Set random seed to 280748612, deterministic: False
2022-07-13 19:09:01,035 - mmdet - INFO - initialize CSPDarknet with init_cfg {'type': 'Kaiming', 'layer': 'Conv2d', 'a': 2.23606797749979, 'distribution': 'uniform', 'mode': 'fan_in', 'nonlinearity': 'leaky_relu'}
2022-07-13 19:09:01,132 - mmdet - INFO - initialize YOLOXPAFPN with init_cfg {'type': 'Kaiming', 'layer': 'Conv2d', 'a': 2.23606797749979, 'distribution': 'uniform', 'mode': 'fan_in', 'nonlinearity': 'leaky_relu'}
2022-07-13 19:09:01,204 - mmdet - INFO - initialize YOLOXHead with init_cfg {'type': 'Kaiming', 'layer': 'Conv2d', 'a': 2.23606797749979, 'distribution': 'uniform', 'mode': 'fan_in', 'nonlinearity': 'leaky_relu'}
Name of parameter - Initialization information

backbone.stem.conv.conv.weight - torch.Size([64, 12, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stem.conv.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stem.conv.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage1.0.conv.weight - torch.Size([128, 64, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage1.0.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage1.0.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage1.1.main_conv.conv.weight - torch.Size([64, 128, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage1.1.main_conv.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage1.1.main_conv.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage1.1.short_conv.conv.weight - torch.Size([64, 128, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage1.1.short_conv.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage1.1.short_conv.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage1.1.final_conv.conv.weight - torch.Size([128, 128, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage1.1.final_conv.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage1.1.final_conv.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage1.1.blocks.0.conv1.conv.weight - torch.Size([64, 64, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage1.1.blocks.0.conv1.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage1.1.blocks.0.conv1.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage1.1.blocks.0.conv2.conv.weight - torch.Size([64, 64, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage1.1.blocks.0.conv2.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage1.1.blocks.0.conv2.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage1.1.blocks.1.conv1.conv.weight - torch.Size([64, 64, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage1.1.blocks.1.conv1.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage1.1.blocks.1.conv1.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage1.1.blocks.1.conv2.conv.weight - torch.Size([64, 64, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage1.1.blocks.1.conv2.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage1.1.blocks.1.conv2.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage1.1.blocks.2.conv1.conv.weight - torch.Size([64, 64, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage1.1.blocks.2.conv1.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage1.1.blocks.2.conv1.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage1.1.blocks.2.conv2.conv.weight - torch.Size([64, 64, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage1.1.blocks.2.conv2.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage1.1.blocks.2.conv2.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage2.0.conv.weight - torch.Size([256, 128, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.0.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage2.0.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage2.1.main_conv.conv.weight - torch.Size([128, 256, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.main_conv.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage2.1.main_conv.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage2.1.short_conv.conv.weight - torch.Size([128, 256, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.short_conv.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage2.1.short_conv.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage2.1.final_conv.conv.weight - torch.Size([256, 256, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.final_conv.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage2.1.final_conv.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage2.1.blocks.0.conv1.conv.weight - torch.Size([128, 128, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.0.conv1.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage2.1.blocks.0.conv1.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage2.1.blocks.0.conv2.conv.weight - torch.Size([128, 128, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.0.conv2.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage2.1.blocks.0.conv2.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage2.1.blocks.1.conv1.conv.weight - torch.Size([128, 128, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.1.conv1.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage2.1.blocks.1.conv1.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage2.1.blocks.1.conv2.conv.weight - torch.Size([128, 128, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.1.conv2.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage2.1.blocks.1.conv2.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage2.1.blocks.2.conv1.conv.weight - torch.Size([128, 128, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.2.conv1.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage2.1.blocks.2.conv1.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage2.1.blocks.2.conv2.conv.weight - torch.Size([128, 128, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.2.conv2.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage2.1.blocks.2.conv2.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage2.1.blocks.3.conv1.conv.weight - torch.Size([128, 128, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.3.conv1.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage2.1.blocks.3.conv1.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage2.1.blocks.3.conv2.conv.weight - torch.Size([128, 128, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.3.conv2.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage2.1.blocks.3.conv2.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage2.1.blocks.4.conv1.conv.weight - torch.Size([128, 128, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.4.conv1.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage2.1.blocks.4.conv1.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage2.1.blocks.4.conv2.conv.weight - torch.Size([128, 128, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.4.conv2.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage2.1.blocks.4.conv2.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage2.1.blocks.5.conv1.conv.weight - torch.Size([128, 128, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.5.conv1.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage2.1.blocks.5.conv1.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage2.1.blocks.5.conv2.conv.weight - torch.Size([128, 128, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.5.conv2.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage2.1.blocks.5.conv2.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage2.1.blocks.6.conv1.conv.weight - torch.Size([128, 128, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.6.conv1.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage2.1.blocks.6.conv1.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage2.1.blocks.6.conv2.conv.weight - torch.Size([128, 128, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.6.conv2.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage2.1.blocks.6.conv2.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage2.1.blocks.7.conv1.conv.weight - torch.Size([128, 128, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.7.conv1.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage2.1.blocks.7.conv1.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage2.1.blocks.7.conv2.conv.weight - torch.Size([128, 128, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.7.conv2.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage2.1.blocks.7.conv2.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage2.1.blocks.8.conv1.conv.weight - torch.Size([128, 128, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.8.conv1.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage2.1.blocks.8.conv1.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage2.1.blocks.8.conv2.conv.weight - torch.Size([128, 128, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage2.1.blocks.8.conv2.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage2.1.blocks.8.conv2.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage3.0.conv.weight - torch.Size([512, 256, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.0.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage3.0.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage3.1.main_conv.conv.weight - torch.Size([256, 512, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.main_conv.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage3.1.main_conv.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage3.1.short_conv.conv.weight - torch.Size([256, 512, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.short_conv.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage3.1.short_conv.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage3.1.final_conv.conv.weight - torch.Size([512, 512, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.final_conv.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage3.1.final_conv.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage3.1.blocks.0.conv1.conv.weight - torch.Size([256, 256, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.0.conv1.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage3.1.blocks.0.conv1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage3.1.blocks.0.conv2.conv.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.0.conv2.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage3.1.blocks.0.conv2.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage3.1.blocks.1.conv1.conv.weight - torch.Size([256, 256, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.1.conv1.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage3.1.blocks.1.conv1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage3.1.blocks.1.conv2.conv.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.1.conv2.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage3.1.blocks.1.conv2.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage3.1.blocks.2.conv1.conv.weight - torch.Size([256, 256, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.2.conv1.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage3.1.blocks.2.conv1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage3.1.blocks.2.conv2.conv.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.2.conv2.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage3.1.blocks.2.conv2.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage3.1.blocks.3.conv1.conv.weight - torch.Size([256, 256, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.3.conv1.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage3.1.blocks.3.conv1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage3.1.blocks.3.conv2.conv.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.3.conv2.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage3.1.blocks.3.conv2.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage3.1.blocks.4.conv1.conv.weight - torch.Size([256, 256, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.4.conv1.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage3.1.blocks.4.conv1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage3.1.blocks.4.conv2.conv.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.4.conv2.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage3.1.blocks.4.conv2.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage3.1.blocks.5.conv1.conv.weight - torch.Size([256, 256, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.5.conv1.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage3.1.blocks.5.conv1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage3.1.blocks.5.conv2.conv.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.5.conv2.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage3.1.blocks.5.conv2.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage3.1.blocks.6.conv1.conv.weight - torch.Size([256, 256, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.6.conv1.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage3.1.blocks.6.conv1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage3.1.blocks.6.conv2.conv.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.6.conv2.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage3.1.blocks.6.conv2.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage3.1.blocks.7.conv1.conv.weight - torch.Size([256, 256, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.7.conv1.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage3.1.blocks.7.conv1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage3.1.blocks.7.conv2.conv.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.7.conv2.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage3.1.blocks.7.conv2.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage3.1.blocks.8.conv1.conv.weight - torch.Size([256, 256, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.8.conv1.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage3.1.blocks.8.conv1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage3.1.blocks.8.conv2.conv.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage3.1.blocks.8.conv2.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage3.1.blocks.8.conv2.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage4.0.conv.weight - torch.Size([1024, 512, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.0.bn.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage4.0.bn.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage4.1.conv1.conv.weight - torch.Size([512, 1024, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.1.conv1.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage4.1.conv1.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage4.1.conv2.conv.weight - torch.Size([1024, 2048, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.1.conv2.bn.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage4.1.conv2.bn.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage4.2.main_conv.conv.weight - torch.Size([512, 1024, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.2.main_conv.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage4.2.main_conv.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage4.2.short_conv.conv.weight - torch.Size([512, 1024, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.2.short_conv.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage4.2.short_conv.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage4.2.final_conv.conv.weight - torch.Size([1024, 1024, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.2.final_conv.bn.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage4.2.final_conv.bn.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage4.2.blocks.0.conv1.conv.weight - torch.Size([512, 512, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.2.blocks.0.conv1.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage4.2.blocks.0.conv1.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage4.2.blocks.0.conv2.conv.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.2.blocks.0.conv2.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage4.2.blocks.0.conv2.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage4.2.blocks.1.conv1.conv.weight - torch.Size([512, 512, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.2.blocks.1.conv1.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage4.2.blocks.1.conv1.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage4.2.blocks.1.conv2.conv.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.2.blocks.1.conv2.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage4.2.blocks.1.conv2.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage4.2.blocks.2.conv1.conv.weight - torch.Size([512, 512, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.2.blocks.2.conv1.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage4.2.blocks.2.conv1.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage4.2.blocks.2.conv2.conv.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

backbone.stage4.2.blocks.2.conv2.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of YOLOX  

backbone.stage4.2.blocks.2.conv2.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.reduce_layers.0.conv.weight - torch.Size([512, 1024, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.reduce_layers.0.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.reduce_layers.0.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.reduce_layers.1.conv.weight - torch.Size([256, 512, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.reduce_layers.1.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.reduce_layers.1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.top_down_blocks.0.main_conv.conv.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.0.main_conv.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.top_down_blocks.0.main_conv.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.top_down_blocks.0.short_conv.conv.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.0.short_conv.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.top_down_blocks.0.short_conv.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.top_down_blocks.0.final_conv.conv.weight - torch.Size([512, 512, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.0.final_conv.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.top_down_blocks.0.final_conv.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.top_down_blocks.0.blocks.0.conv1.conv.weight - torch.Size([256, 256, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.0.blocks.0.conv1.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.top_down_blocks.0.blocks.0.conv1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.top_down_blocks.0.blocks.0.conv2.conv.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.0.blocks.0.conv2.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.top_down_blocks.0.blocks.0.conv2.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.top_down_blocks.0.blocks.1.conv1.conv.weight - torch.Size([256, 256, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.0.blocks.1.conv1.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.top_down_blocks.0.blocks.1.conv1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.top_down_blocks.0.blocks.1.conv2.conv.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.0.blocks.1.conv2.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.top_down_blocks.0.blocks.1.conv2.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.top_down_blocks.0.blocks.2.conv1.conv.weight - torch.Size([256, 256, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.0.blocks.2.conv1.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.top_down_blocks.0.blocks.2.conv1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.top_down_blocks.0.blocks.2.conv2.conv.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.0.blocks.2.conv2.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.top_down_blocks.0.blocks.2.conv2.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.top_down_blocks.1.main_conv.conv.weight - torch.Size([128, 512, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.1.main_conv.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.top_down_blocks.1.main_conv.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.top_down_blocks.1.short_conv.conv.weight - torch.Size([128, 512, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.1.short_conv.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.top_down_blocks.1.short_conv.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.top_down_blocks.1.final_conv.conv.weight - torch.Size([256, 256, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.1.final_conv.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.top_down_blocks.1.final_conv.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.top_down_blocks.1.blocks.0.conv1.conv.weight - torch.Size([128, 128, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.1.blocks.0.conv1.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.top_down_blocks.1.blocks.0.conv1.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.top_down_blocks.1.blocks.0.conv2.conv.weight - torch.Size([128, 128, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.1.blocks.0.conv2.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.top_down_blocks.1.blocks.0.conv2.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.top_down_blocks.1.blocks.1.conv1.conv.weight - torch.Size([128, 128, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.1.blocks.1.conv1.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.top_down_blocks.1.blocks.1.conv1.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.top_down_blocks.1.blocks.1.conv2.conv.weight - torch.Size([128, 128, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.1.blocks.1.conv2.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.top_down_blocks.1.blocks.1.conv2.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.top_down_blocks.1.blocks.2.conv1.conv.weight - torch.Size([128, 128, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.1.blocks.2.conv1.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.top_down_blocks.1.blocks.2.conv1.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.top_down_blocks.1.blocks.2.conv2.conv.weight - torch.Size([128, 128, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.top_down_blocks.1.blocks.2.conv2.bn.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.top_down_blocks.1.blocks.2.conv2.bn.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.downsamples.0.conv.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.downsamples.0.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.downsamples.0.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.downsamples.1.conv.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.downsamples.1.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.downsamples.1.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.bottom_up_blocks.0.main_conv.conv.weight - torch.Size([256, 512, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.0.main_conv.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.bottom_up_blocks.0.main_conv.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.bottom_up_blocks.0.short_conv.conv.weight - torch.Size([256, 512, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.0.short_conv.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.bottom_up_blocks.0.short_conv.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.bottom_up_blocks.0.final_conv.conv.weight - torch.Size([512, 512, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.0.final_conv.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.bottom_up_blocks.0.final_conv.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.bottom_up_blocks.0.blocks.0.conv1.conv.weight - torch.Size([256, 256, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.0.blocks.0.conv1.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.bottom_up_blocks.0.blocks.0.conv1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.bottom_up_blocks.0.blocks.0.conv2.conv.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.0.blocks.0.conv2.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.bottom_up_blocks.0.blocks.0.conv2.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.bottom_up_blocks.0.blocks.1.conv1.conv.weight - torch.Size([256, 256, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.0.blocks.1.conv1.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.bottom_up_blocks.0.blocks.1.conv1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.bottom_up_blocks.0.blocks.1.conv2.conv.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.0.blocks.1.conv2.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.bottom_up_blocks.0.blocks.1.conv2.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.bottom_up_blocks.0.blocks.2.conv1.conv.weight - torch.Size([256, 256, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.0.blocks.2.conv1.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.bottom_up_blocks.0.blocks.2.conv1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.bottom_up_blocks.0.blocks.2.conv2.conv.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.0.blocks.2.conv2.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.bottom_up_blocks.0.blocks.2.conv2.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.bottom_up_blocks.1.main_conv.conv.weight - torch.Size([512, 1024, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.1.main_conv.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.bottom_up_blocks.1.main_conv.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.bottom_up_blocks.1.short_conv.conv.weight - torch.Size([512, 1024, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.1.short_conv.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.bottom_up_blocks.1.short_conv.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.bottom_up_blocks.1.final_conv.conv.weight - torch.Size([1024, 1024, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.1.final_conv.bn.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.bottom_up_blocks.1.final_conv.bn.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.bottom_up_blocks.1.blocks.0.conv1.conv.weight - torch.Size([512, 512, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.1.blocks.0.conv1.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.bottom_up_blocks.1.blocks.0.conv1.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.bottom_up_blocks.1.blocks.0.conv2.conv.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.1.blocks.0.conv2.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.bottom_up_blocks.1.blocks.0.conv2.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.bottom_up_blocks.1.blocks.1.conv1.conv.weight - torch.Size([512, 512, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.1.blocks.1.conv1.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.bottom_up_blocks.1.blocks.1.conv1.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.bottom_up_blocks.1.blocks.1.conv2.conv.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.1.blocks.1.conv2.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.bottom_up_blocks.1.blocks.1.conv2.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.bottom_up_blocks.1.blocks.2.conv1.conv.weight - torch.Size([512, 512, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.1.blocks.2.conv1.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.bottom_up_blocks.1.blocks.2.conv1.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.bottom_up_blocks.1.blocks.2.conv2.conv.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.bottom_up_blocks.1.blocks.2.conv2.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.bottom_up_blocks.1.blocks.2.conv2.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.out_convs.0.conv.weight - torch.Size([256, 256, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.out_convs.0.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.out_convs.0.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.out_convs.1.conv.weight - torch.Size([256, 512, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.out_convs.1.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.out_convs.1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.out_convs.2.conv.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

neck.out_convs.2.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

neck.out_convs.2.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

bbox_head.multi_level_cls_convs.0.0.conv.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

bbox_head.multi_level_cls_convs.0.0.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

bbox_head.multi_level_cls_convs.0.0.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

bbox_head.multi_level_cls_convs.0.1.conv.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

bbox_head.multi_level_cls_convs.0.1.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

bbox_head.multi_level_cls_convs.0.1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

bbox_head.multi_level_cls_convs.1.0.conv.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

bbox_head.multi_level_cls_convs.1.0.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

bbox_head.multi_level_cls_convs.1.0.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

bbox_head.multi_level_cls_convs.1.1.conv.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

bbox_head.multi_level_cls_convs.1.1.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

bbox_head.multi_level_cls_convs.1.1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

bbox_head.multi_level_cls_convs.2.0.conv.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

bbox_head.multi_level_cls_convs.2.0.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

bbox_head.multi_level_cls_convs.2.0.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

bbox_head.multi_level_cls_convs.2.1.conv.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

bbox_head.multi_level_cls_convs.2.1.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

bbox_head.multi_level_cls_convs.2.1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

bbox_head.multi_level_reg_convs.0.0.conv.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

bbox_head.multi_level_reg_convs.0.0.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

bbox_head.multi_level_reg_convs.0.0.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

bbox_head.multi_level_reg_convs.0.1.conv.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

bbox_head.multi_level_reg_convs.0.1.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

bbox_head.multi_level_reg_convs.0.1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

bbox_head.multi_level_reg_convs.1.0.conv.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

bbox_head.multi_level_reg_convs.1.0.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

bbox_head.multi_level_reg_convs.1.0.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

bbox_head.multi_level_reg_convs.1.1.conv.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

bbox_head.multi_level_reg_convs.1.1.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

bbox_head.multi_level_reg_convs.1.1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

bbox_head.multi_level_reg_convs.2.0.conv.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

bbox_head.multi_level_reg_convs.2.0.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

bbox_head.multi_level_reg_convs.2.0.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

bbox_head.multi_level_reg_convs.2.1.conv.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

bbox_head.multi_level_reg_convs.2.1.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

bbox_head.multi_level_reg_convs.2.1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of YOLOX  

bbox_head.multi_level_conv_cls.0.weight - torch.Size([1, 256, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

bbox_head.multi_level_conv_cls.0.bias - torch.Size([1]): 
Initialized by user-defined `init_weights` in YOLOXHead  

bbox_head.multi_level_conv_cls.1.weight - torch.Size([1, 256, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

bbox_head.multi_level_conv_cls.1.bias - torch.Size([1]): 
Initialized by user-defined `init_weights` in YOLOXHead  

bbox_head.multi_level_conv_cls.2.weight - torch.Size([1, 256, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

bbox_head.multi_level_conv_cls.2.bias - torch.Size([1]): 
Initialized by user-defined `init_weights` in YOLOXHead  

bbox_head.multi_level_conv_reg.0.weight - torch.Size([4, 256, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

bbox_head.multi_level_conv_reg.0.bias - torch.Size([4]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

bbox_head.multi_level_conv_reg.1.weight - torch.Size([4, 256, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

bbox_head.multi_level_conv_reg.1.bias - torch.Size([4]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

bbox_head.multi_level_conv_reg.2.weight - torch.Size([4, 256, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

bbox_head.multi_level_conv_reg.2.bias - torch.Size([4]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

bbox_head.multi_level_conv_obj.0.weight - torch.Size([1, 256, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

bbox_head.multi_level_conv_obj.0.bias - torch.Size([1]): 
Initialized by user-defined `init_weights` in YOLOXHead  

bbox_head.multi_level_conv_obj.1.weight - torch.Size([1, 256, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

bbox_head.multi_level_conv_obj.1.bias - torch.Size([1]): 
Initialized by user-defined `init_weights` in YOLOXHead  

bbox_head.multi_level_conv_obj.2.weight - torch.Size([1, 256, 1, 1]): 
KaimingInit: a=2.23606797749979, mode=fan_in, nonlinearity=leaky_relu, distribution =uniform, bias=0 

bbox_head.multi_level_conv_obj.2.bias - torch.Size([1]): 
Initialized by user-defined `init_weights` in YOLOXHead  
2022-07-13 19:09:03,773 - mmdet - INFO - load checkpoint from local path: /home/naama/Documents/MyProjects/ml_projects/ml_detection/ml_detection/work_dirs/yolox_l_8x8_300e_coco_airbus/epoch_280.pth
2022-07-13 19:09:04,173 - mmdet - WARNING - The model and loaded state dict do not match exactly

unexpected key in source state_dict: ema_backbone_stem_conv_conv_weight, ema_backbone_stem_conv_bn_weight, ema_backbone_stem_conv_bn_bias, ema_backbone_stem_conv_bn_running_mean, ema_backbone_stem_conv_bn_running_var, ema_backbone_stem_conv_bn_num_batches_tracked, ema_backbone_stage1_0_conv_weight, ema_backbone_stage1_0_bn_weight, ema_backbone_stage1_0_bn_bias, ema_backbone_stage1_0_bn_running_mean, ema_backbone_stage1_0_bn_running_var, ema_backbone_stage1_0_bn_num_batches_tracked, ema_backbone_stage1_1_main_conv_conv_weight, ema_backbone_stage1_1_main_conv_bn_weight, ema_backbone_stage1_1_main_conv_bn_bias, ema_backbone_stage1_1_main_conv_bn_running_mean, ema_backbone_stage1_1_main_conv_bn_running_var, ema_backbone_stage1_1_main_conv_bn_num_batches_tracked, ema_backbone_stage1_1_short_conv_conv_weight, ema_backbone_stage1_1_short_conv_bn_weight, ema_backbone_stage1_1_short_conv_bn_bias, ema_backbone_stage1_1_short_conv_bn_running_mean, ema_backbone_stage1_1_short_conv_bn_running_var, ema_backbone_stage1_1_short_conv_bn_num_batches_tracked, ema_backbone_stage1_1_final_conv_conv_weight, ema_backbone_stage1_1_final_conv_bn_weight, ema_backbone_stage1_1_final_conv_bn_bias, ema_backbone_stage1_1_final_conv_bn_running_mean, ema_backbone_stage1_1_final_conv_bn_running_var, ema_backbone_stage1_1_final_conv_bn_num_batches_tracked, ema_backbone_stage1_1_blocks_0_conv1_conv_weight, ema_backbone_stage1_1_blocks_0_conv1_bn_weight, ema_backbone_stage1_1_blocks_0_conv1_bn_bias, ema_backbone_stage1_1_blocks_0_conv1_bn_running_mean, ema_backbone_stage1_1_blocks_0_conv1_bn_running_var, ema_backbone_stage1_1_blocks_0_conv1_bn_num_batches_tracked, ema_backbone_stage1_1_blocks_0_conv2_conv_weight, ema_backbone_stage1_1_blocks_0_conv2_bn_weight, ema_backbone_stage1_1_blocks_0_conv2_bn_bias, ema_backbone_stage1_1_blocks_0_conv2_bn_running_mean, ema_backbone_stage1_1_blocks_0_conv2_bn_running_var, ema_backbone_stage1_1_blocks_0_conv2_bn_num_batches_tracked, ema_backbone_stage1_1_blocks_1_conv1_conv_weight, ema_backbone_stage1_1_blocks_1_conv1_bn_weight, ema_backbone_stage1_1_blocks_1_conv1_bn_bias, ema_backbone_stage1_1_blocks_1_conv1_bn_running_mean, ema_backbone_stage1_1_blocks_1_conv1_bn_running_var, ema_backbone_stage1_1_blocks_1_conv1_bn_num_batches_tracked, ema_backbone_stage1_1_blocks_1_conv2_conv_weight, ema_backbone_stage1_1_blocks_1_conv2_bn_weight, ema_backbone_stage1_1_blocks_1_conv2_bn_bias, ema_backbone_stage1_1_blocks_1_conv2_bn_running_mean, ema_backbone_stage1_1_blocks_1_conv2_bn_running_var, ema_backbone_stage1_1_blocks_1_conv2_bn_num_batches_tracked, ema_backbone_stage1_1_blocks_2_conv1_conv_weight, ema_backbone_stage1_1_blocks_2_conv1_bn_weight, ema_backbone_stage1_1_blocks_2_conv1_bn_bias, ema_backbone_stage1_1_blocks_2_conv1_bn_running_mean, ema_backbone_stage1_1_blocks_2_conv1_bn_running_var, ema_backbone_stage1_1_blocks_2_conv1_bn_num_batches_tracked, ema_backbone_stage1_1_blocks_2_conv2_conv_weight, ema_backbone_stage1_1_blocks_2_conv2_bn_weight, ema_backbone_stage1_1_blocks_2_conv2_bn_bias, ema_backbone_stage1_1_blocks_2_conv2_bn_running_mean, ema_backbone_stage1_1_blocks_2_conv2_bn_running_var, ema_backbone_stage1_1_blocks_2_conv2_bn_num_batches_tracked, ema_backbone_stage2_0_conv_weight, ema_backbone_stage2_0_bn_weight, ema_backbone_stage2_0_bn_bias, ema_backbone_stage2_0_bn_running_mean, ema_backbone_stage2_0_bn_running_var, ema_backbone_stage2_0_bn_num_batches_tracked, ema_backbone_stage2_1_main_conv_conv_weight, ema_backbone_stage2_1_main_conv_bn_weight, ema_backbone_stage2_1_main_conv_bn_bias, ema_backbone_stage2_1_main_conv_bn_running_mean, ema_backbone_stage2_1_main_conv_bn_running_var, ema_backbone_stage2_1_main_conv_bn_num_batches_tracked, ema_backbone_stage2_1_short_conv_conv_weight, ema_backbone_stage2_1_short_conv_bn_weight, ema_backbone_stage2_1_short_conv_bn_bias, ema_backbone_stage2_1_short_conv_bn_running_mean, ema_backbone_stage2_1_short_conv_bn_running_var, ema_backbone_stage2_1_short_conv_bn_num_batches_tracked, ema_backbone_stage2_1_final_conv_conv_weight, ema_backbone_stage2_1_final_conv_bn_weight, ema_backbone_stage2_1_final_conv_bn_bias, ema_backbone_stage2_1_final_conv_bn_running_mean, ema_backbone_stage2_1_final_conv_bn_running_var, ema_backbone_stage2_1_final_conv_bn_num_batches_tracked, ema_backbone_stage2_1_blocks_0_conv1_conv_weight, ema_backbone_stage2_1_blocks_0_conv1_bn_weight, ema_backbone_stage2_1_blocks_0_conv1_bn_bias, ema_backbone_stage2_1_blocks_0_conv1_bn_running_mean, ema_backbone_stage2_1_blocks_0_conv1_bn_running_var, ema_backbone_stage2_1_blocks_0_conv1_bn_num_batches_tracked, ema_backbone_stage2_1_blocks_0_conv2_conv_weight, ema_backbone_stage2_1_blocks_0_conv2_bn_weight, ema_backbone_stage2_1_blocks_0_conv2_bn_bias, ema_backbone_stage2_1_blocks_0_conv2_bn_running_mean, ema_backbone_stage2_1_blocks_0_conv2_bn_running_var, ema_backbone_stage2_1_blocks_0_conv2_bn_num_batches_tracked, ema_backbone_stage2_1_blocks_1_conv1_conv_weight, ema_backbone_stage2_1_blocks_1_conv1_bn_weight, ema_backbone_stage2_1_blocks_1_conv1_bn_bias, ema_backbone_stage2_1_blocks_1_conv1_bn_running_mean, ema_backbone_stage2_1_blocks_1_conv1_bn_running_var, ema_backbone_stage2_1_blocks_1_conv1_bn_num_batches_tracked, ema_backbone_stage2_1_blocks_1_conv2_conv_weight, ema_backbone_stage2_1_blocks_1_conv2_bn_weight, ema_backbone_stage2_1_blocks_1_conv2_bn_bias, ema_backbone_stage2_1_blocks_1_conv2_bn_running_mean, ema_backbone_stage2_1_blocks_1_conv2_bn_running_var, ema_backbone_stage2_1_blocks_1_conv2_bn_num_batches_tracked, ema_backbone_stage2_1_blocks_2_conv1_conv_weight, ema_backbone_stage2_1_blocks_2_conv1_bn_weight, ema_backbone_stage2_1_blocks_2_conv1_bn_bias, ema_backbone_stage2_1_blocks_2_conv1_bn_running_mean, ema_backbone_stage2_1_blocks_2_conv1_bn_running_var, ema_backbone_stage2_1_blocks_2_conv1_bn_num_batches_tracked, ema_backbone_stage2_1_blocks_2_conv2_conv_weight, ema_backbone_stage2_1_blocks_2_conv2_bn_weight, ema_backbone_stage2_1_blocks_2_conv2_bn_bias, ema_backbone_stage2_1_blocks_2_conv2_bn_running_mean, ema_backbone_stage2_1_blocks_2_conv2_bn_running_var, ema_backbone_stage2_1_blocks_2_conv2_bn_num_batches_tracked, ema_backbone_stage2_1_blocks_3_conv1_conv_weight, ema_backbone_stage2_1_blocks_3_conv1_bn_weight, ema_backbone_stage2_1_blocks_3_conv1_bn_bias, ema_backbone_stage2_1_blocks_3_conv1_bn_running_mean, ema_backbone_stage2_1_blocks_3_conv1_bn_running_var, ema_backbone_stage2_1_blocks_3_conv1_bn_num_batches_tracked, ema_backbone_stage2_1_blocks_3_conv2_conv_weight, ema_backbone_stage2_1_blocks_3_conv2_bn_weight, ema_backbone_stage2_1_blocks_3_conv2_bn_bias, ema_backbone_stage2_1_blocks_3_conv2_bn_running_mean, ema_backbone_stage2_1_blocks_3_conv2_bn_running_var, ema_backbone_stage2_1_blocks_3_conv2_bn_num_batches_tracked, ema_backbone_stage2_1_blocks_4_conv1_conv_weight, ema_backbone_stage2_1_blocks_4_conv1_bn_weight, ema_backbone_stage2_1_blocks_4_conv1_bn_bias, ema_backbone_stage2_1_blocks_4_conv1_bn_running_mean, ema_backbone_stage2_1_blocks_4_conv1_bn_running_var, ema_backbone_stage2_1_blocks_4_conv1_bn_num_batches_tracked, ema_backbone_stage2_1_blocks_4_conv2_conv_weight, ema_backbone_stage2_1_blocks_4_conv2_bn_weight, ema_backbone_stage2_1_blocks_4_conv2_bn_bias, ema_backbone_stage2_1_blocks_4_conv2_bn_running_mean, ema_backbone_stage2_1_blocks_4_conv2_bn_running_var, ema_backbone_stage2_1_blocks_4_conv2_bn_num_batches_tracked, ema_backbone_stage2_1_blocks_5_conv1_conv_weight, ema_backbone_stage2_1_blocks_5_conv1_bn_weight, ema_backbone_stage2_1_blocks_5_conv1_bn_bias, ema_backbone_stage2_1_blocks_5_conv1_bn_running_mean, ema_backbone_stage2_1_blocks_5_conv1_bn_running_var, ema_backbone_stage2_1_blocks_5_conv1_bn_num_batches_tracked, ema_backbone_stage2_1_blocks_5_conv2_conv_weight, ema_backbone_stage2_1_blocks_5_conv2_bn_weight, ema_backbone_stage2_1_blocks_5_conv2_bn_bias, ema_backbone_stage2_1_blocks_5_conv2_bn_running_mean, ema_backbone_stage2_1_blocks_5_conv2_bn_running_var, ema_backbone_stage2_1_blocks_5_conv2_bn_num_batches_tracked, ema_backbone_stage2_1_blocks_6_conv1_conv_weight, ema_backbone_stage2_1_blocks_6_conv1_bn_weight, ema_backbone_stage2_1_blocks_6_conv1_bn_bias, ema_backbone_stage2_1_blocks_6_conv1_bn_running_mean, ema_backbone_stage2_1_blocks_6_conv1_bn_running_var, ema_backbone_stage2_1_blocks_6_conv1_bn_num_batches_tracked, ema_backbone_stage2_1_blocks_6_conv2_conv_weight, ema_backbone_stage2_1_blocks_6_conv2_bn_weight, ema_backbone_stage2_1_blocks_6_conv2_bn_bias, ema_backbone_stage2_1_blocks_6_conv2_bn_running_mean, ema_backbone_stage2_1_blocks_6_conv2_bn_running_var, ema_backbone_stage2_1_blocks_6_conv2_bn_num_batches_tracked, ema_backbone_stage2_1_blocks_7_conv1_conv_weight, ema_backbone_stage2_1_blocks_7_conv1_bn_weight, ema_backbone_stage2_1_blocks_7_conv1_bn_bias, ema_backbone_stage2_1_blocks_7_conv1_bn_running_mean, ema_backbone_stage2_1_blocks_7_conv1_bn_running_var, ema_backbone_stage2_1_blocks_7_conv1_bn_num_batches_tracked, ema_backbone_stage2_1_blocks_7_conv2_conv_weight, ema_backbone_stage2_1_blocks_7_conv2_bn_weight, ema_backbone_stage2_1_blocks_7_conv2_bn_bias, ema_backbone_stage2_1_blocks_7_conv2_bn_running_mean, ema_backbone_stage2_1_blocks_7_conv2_bn_running_var, ema_backbone_stage2_1_blocks_7_conv2_bn_num_batches_tracked, ema_backbone_stage2_1_blocks_8_conv1_conv_weight, ema_backbone_stage2_1_blocks_8_conv1_bn_weight, ema_backbone_stage2_1_blocks_8_conv1_bn_bias, ema_backbone_stage2_1_blocks_8_conv1_bn_running_mean, ema_backbone_stage2_1_blocks_8_conv1_bn_running_var, ema_backbone_stage2_1_blocks_8_conv1_bn_num_batches_tracked, ema_backbone_stage2_1_blocks_8_conv2_conv_weight, ema_backbone_stage2_1_blocks_8_conv2_bn_weight, ema_backbone_stage2_1_blocks_8_conv2_bn_bias, ema_backbone_stage2_1_blocks_8_conv2_bn_running_mean, ema_backbone_stage2_1_blocks_8_conv2_bn_running_var, ema_backbone_stage2_1_blocks_8_conv2_bn_num_batches_tracked, ema_backbone_stage3_0_conv_weight, ema_backbone_stage3_0_bn_weight, ema_backbone_stage3_0_bn_bias, ema_backbone_stage3_0_bn_running_mean, ema_backbone_stage3_0_bn_running_var, ema_backbone_stage3_0_bn_num_batches_tracked, ema_backbone_stage3_1_main_conv_conv_weight, ema_backbone_stage3_1_main_conv_bn_weight, ema_backbone_stage3_1_main_conv_bn_bias, ema_backbone_stage3_1_main_conv_bn_running_mean, ema_backbone_stage3_1_main_conv_bn_running_var, ema_backbone_stage3_1_main_conv_bn_num_batches_tracked, ema_backbone_stage3_1_short_conv_conv_weight, ema_backbone_stage3_1_short_conv_bn_weight, ema_backbone_stage3_1_short_conv_bn_bias, ema_backbone_stage3_1_short_conv_bn_running_mean, ema_backbone_stage3_1_short_conv_bn_running_var, ema_backbone_stage3_1_short_conv_bn_num_batches_tracked, ema_backbone_stage3_1_final_conv_conv_weight, ema_backbone_stage3_1_final_conv_bn_weight, ema_backbone_stage3_1_final_conv_bn_bias, ema_backbone_stage3_1_final_conv_bn_running_mean, ema_backbone_stage3_1_final_conv_bn_running_var, ema_backbone_stage3_1_final_conv_bn_num_batches_tracked, ema_backbone_stage3_1_blocks_0_conv1_conv_weight, ema_backbone_stage3_1_blocks_0_conv1_bn_weight, ema_backbone_stage3_1_blocks_0_conv1_bn_bias, ema_backbone_stage3_1_blocks_0_conv1_bn_running_mean, ema_backbone_stage3_1_blocks_0_conv1_bn_running_var, ema_backbone_stage3_1_blocks_0_conv1_bn_num_batches_tracked, ema_backbone_stage3_1_blocks_0_conv2_conv_weight, ema_backbone_stage3_1_blocks_0_conv2_bn_weight, ema_backbone_stage3_1_blocks_0_conv2_bn_bias, ema_backbone_stage3_1_blocks_0_conv2_bn_running_mean, ema_backbone_stage3_1_blocks_0_conv2_bn_running_var, ema_backbone_stage3_1_blocks_0_conv2_bn_num_batches_tracked, ema_backbone_stage3_1_blocks_1_conv1_conv_weight, ema_backbone_stage3_1_blocks_1_conv1_bn_weight, ema_backbone_stage3_1_blocks_1_conv1_bn_bias, ema_backbone_stage3_1_blocks_1_conv1_bn_running_mean, ema_backbone_stage3_1_blocks_1_conv1_bn_running_var, ema_backbone_stage3_1_blocks_1_conv1_bn_num_batches_tracked, ema_backbone_stage3_1_blocks_1_conv2_conv_weight, ema_backbone_stage3_1_blocks_1_conv2_bn_weight, ema_backbone_stage3_1_blocks_1_conv2_bn_bias, ema_backbone_stage3_1_blocks_1_conv2_bn_running_mean, ema_backbone_stage3_1_blocks_1_conv2_bn_running_var, ema_backbone_stage3_1_blocks_1_conv2_bn_num_batches_tracked, ema_backbone_stage3_1_blocks_2_conv1_conv_weight, ema_backbone_stage3_1_blocks_2_conv1_bn_weight, ema_backbone_stage3_1_blocks_2_conv1_bn_bias, ema_backbone_stage3_1_blocks_2_conv1_bn_running_mean, ema_backbone_stage3_1_blocks_2_conv1_bn_running_var, ema_backbone_stage3_1_blocks_2_conv1_bn_num_batches_tracked, ema_backbone_stage3_1_blocks_2_conv2_conv_weight, ema_backbone_stage3_1_blocks_2_conv2_bn_weight, ema_backbone_stage3_1_blocks_2_conv2_bn_bias, ema_backbone_stage3_1_blocks_2_conv2_bn_running_mean, ema_backbone_stage3_1_blocks_2_conv2_bn_running_var, ema_backbone_stage3_1_blocks_2_conv2_bn_num_batches_tracked, ema_backbone_stage3_1_blocks_3_conv1_conv_weight, ema_backbone_stage3_1_blocks_3_conv1_bn_weight, ema_backbone_stage3_1_blocks_3_conv1_bn_bias, ema_backbone_stage3_1_blocks_3_conv1_bn_running_mean, ema_backbone_stage3_1_blocks_3_conv1_bn_running_var, ema_backbone_stage3_1_blocks_3_conv1_bn_num_batches_tracked, ema_backbone_stage3_1_blocks_3_conv2_conv_weight, ema_backbone_stage3_1_blocks_3_conv2_bn_weight, ema_backbone_stage3_1_blocks_3_conv2_bn_bias, ema_backbone_stage3_1_blocks_3_conv2_bn_running_mean, ema_backbone_stage3_1_blocks_3_conv2_bn_running_var, ema_backbone_stage3_1_blocks_3_conv2_bn_num_batches_tracked, ema_backbone_stage3_1_blocks_4_conv1_conv_weight, ema_backbone_stage3_1_blocks_4_conv1_bn_weight, ema_backbone_stage3_1_blocks_4_conv1_bn_bias, ema_backbone_stage3_1_blocks_4_conv1_bn_running_mean, ema_backbone_stage3_1_blocks_4_conv1_bn_running_var, ema_backbone_stage3_1_blocks_4_conv1_bn_num_batches_tracked, ema_backbone_stage3_1_blocks_4_conv2_conv_weight, ema_backbone_stage3_1_blocks_4_conv2_bn_weight, ema_backbone_stage3_1_blocks_4_conv2_bn_bias, ema_backbone_stage3_1_blocks_4_conv2_bn_running_mean, ema_backbone_stage3_1_blocks_4_conv2_bn_running_var, ema_backbone_stage3_1_blocks_4_conv2_bn_num_batches_tracked, ema_backbone_stage3_1_blocks_5_conv1_conv_weight, ema_backbone_stage3_1_blocks_5_conv1_bn_weight, ema_backbone_stage3_1_blocks_5_conv1_bn_bias, ema_backbone_stage3_1_blocks_5_conv1_bn_running_mean, ema_backbone_stage3_1_blocks_5_conv1_bn_running_var, ema_backbone_stage3_1_blocks_5_conv1_bn_num_batches_tracked, ema_backbone_stage3_1_blocks_5_conv2_conv_weight, ema_backbone_stage3_1_blocks_5_conv2_bn_weight, ema_backbone_stage3_1_blocks_5_conv2_bn_bias, ema_backbone_stage3_1_blocks_5_conv2_bn_running_mean, ema_backbone_stage3_1_blocks_5_conv2_bn_running_var, ema_backbone_stage3_1_blocks_5_conv2_bn_num_batches_tracked, ema_backbone_stage3_1_blocks_6_conv1_conv_weight, ema_backbone_stage3_1_blocks_6_conv1_bn_weight, ema_backbone_stage3_1_blocks_6_conv1_bn_bias, ema_backbone_stage3_1_blocks_6_conv1_bn_running_mean, ema_backbone_stage3_1_blocks_6_conv1_bn_running_var, ema_backbone_stage3_1_blocks_6_conv1_bn_num_batches_tracked, ema_backbone_stage3_1_blocks_6_conv2_conv_weight, ema_backbone_stage3_1_blocks_6_conv2_bn_weight, ema_backbone_stage3_1_blocks_6_conv2_bn_bias, ema_backbone_stage3_1_blocks_6_conv2_bn_running_mean, ema_backbone_stage3_1_blocks_6_conv2_bn_running_var, ema_backbone_stage3_1_blocks_6_conv2_bn_num_batches_tracked, ema_backbone_stage3_1_blocks_7_conv1_conv_weight, ema_backbone_stage3_1_blocks_7_conv1_bn_weight, ema_backbone_stage3_1_blocks_7_conv1_bn_bias, ema_backbone_stage3_1_blocks_7_conv1_bn_running_mean, ema_backbone_stage3_1_blocks_7_conv1_bn_running_var, ema_backbone_stage3_1_blocks_7_conv1_bn_num_batches_tracked, ema_backbone_stage3_1_blocks_7_conv2_conv_weight, ema_backbone_stage3_1_blocks_7_conv2_bn_weight, ema_backbone_stage3_1_blocks_7_conv2_bn_bias, ema_backbone_stage3_1_blocks_7_conv2_bn_running_mean, ema_backbone_stage3_1_blocks_7_conv2_bn_running_var, ema_backbone_stage3_1_blocks_7_conv2_bn_num_batches_tracked, ema_backbone_stage3_1_blocks_8_conv1_conv_weight, ema_backbone_stage3_1_blocks_8_conv1_bn_weight, ema_backbone_stage3_1_blocks_8_conv1_bn_bias, ema_backbone_stage3_1_blocks_8_conv1_bn_running_mean, ema_backbone_stage3_1_blocks_8_conv1_bn_running_var, ema_backbone_stage3_1_blocks_8_conv1_bn_num_batches_tracked, ema_backbone_stage3_1_blocks_8_conv2_conv_weight, ema_backbone_stage3_1_blocks_8_conv2_bn_weight, ema_backbone_stage3_1_blocks_8_conv2_bn_bias, ema_backbone_stage3_1_blocks_8_conv2_bn_running_mean, ema_backbone_stage3_1_blocks_8_conv2_bn_running_var, ema_backbone_stage3_1_blocks_8_conv2_bn_num_batches_tracked, ema_backbone_stage4_0_conv_weight, ema_backbone_stage4_0_bn_weight, ema_backbone_stage4_0_bn_bias, ema_backbone_stage4_0_bn_running_mean, ema_backbone_stage4_0_bn_running_var, ema_backbone_stage4_0_bn_num_batches_tracked, ema_backbone_stage4_1_conv1_conv_weight, ema_backbone_stage4_1_conv1_bn_weight, ema_backbone_stage4_1_conv1_bn_bias, ema_backbone_stage4_1_conv1_bn_running_mean, ema_backbone_stage4_1_conv1_bn_running_var, ema_backbone_stage4_1_conv1_bn_num_batches_tracked, ema_backbone_stage4_1_conv2_conv_weight, ema_backbone_stage4_1_conv2_bn_weight, ema_backbone_stage4_1_conv2_bn_bias, ema_backbone_stage4_1_conv2_bn_running_mean, ema_backbone_stage4_1_conv2_bn_running_var, ema_backbone_stage4_1_conv2_bn_num_batches_tracked, ema_backbone_stage4_2_main_conv_conv_weight, ema_backbone_stage4_2_main_conv_bn_weight, ema_backbone_stage4_2_main_conv_bn_bias, ema_backbone_stage4_2_main_conv_bn_running_mean, ema_backbone_stage4_2_main_conv_bn_running_var, ema_backbone_stage4_2_main_conv_bn_num_batches_tracked, ema_backbone_stage4_2_short_conv_conv_weight, ema_backbone_stage4_2_short_conv_bn_weight, ema_backbone_stage4_2_short_conv_bn_bias, ema_backbone_stage4_2_short_conv_bn_running_mean, ema_backbone_stage4_2_short_conv_bn_running_var, ema_backbone_stage4_2_short_conv_bn_num_batches_tracked, ema_backbone_stage4_2_final_conv_conv_weight, ema_backbone_stage4_2_final_conv_bn_weight, ema_backbone_stage4_2_final_conv_bn_bias, ema_backbone_stage4_2_final_conv_bn_running_mean, ema_backbone_stage4_2_final_conv_bn_running_var, ema_backbone_stage4_2_final_conv_bn_num_batches_tracked, ema_backbone_stage4_2_blocks_0_conv1_conv_weight, ema_backbone_stage4_2_blocks_0_conv1_bn_weight, ema_backbone_stage4_2_blocks_0_conv1_bn_bias, ema_backbone_stage4_2_blocks_0_conv1_bn_running_mean, ema_backbone_stage4_2_blocks_0_conv1_bn_running_var, ema_backbone_stage4_2_blocks_0_conv1_bn_num_batches_tracked, ema_backbone_stage4_2_blocks_0_conv2_conv_weight, ema_backbone_stage4_2_blocks_0_conv2_bn_weight, ema_backbone_stage4_2_blocks_0_conv2_bn_bias, ema_backbone_stage4_2_blocks_0_conv2_bn_running_mean, ema_backbone_stage4_2_blocks_0_conv2_bn_running_var, ema_backbone_stage4_2_blocks_0_conv2_bn_num_batches_tracked, ema_backbone_stage4_2_blocks_1_conv1_conv_weight, ema_backbone_stage4_2_blocks_1_conv1_bn_weight, ema_backbone_stage4_2_blocks_1_conv1_bn_bias, ema_backbone_stage4_2_blocks_1_conv1_bn_running_mean, ema_backbone_stage4_2_blocks_1_conv1_bn_running_var, ema_backbone_stage4_2_blocks_1_conv1_bn_num_batches_tracked, ema_backbone_stage4_2_blocks_1_conv2_conv_weight, ema_backbone_stage4_2_blocks_1_conv2_bn_weight, ema_backbone_stage4_2_blocks_1_conv2_bn_bias, ema_backbone_stage4_2_blocks_1_conv2_bn_running_mean, ema_backbone_stage4_2_blocks_1_conv2_bn_running_var, ema_backbone_stage4_2_blocks_1_conv2_bn_num_batches_tracked, ema_backbone_stage4_2_blocks_2_conv1_conv_weight, ema_backbone_stage4_2_blocks_2_conv1_bn_weight, ema_backbone_stage4_2_blocks_2_conv1_bn_bias, ema_backbone_stage4_2_blocks_2_conv1_bn_running_mean, ema_backbone_stage4_2_blocks_2_conv1_bn_running_var, ema_backbone_stage4_2_blocks_2_conv1_bn_num_batches_tracked, ema_backbone_stage4_2_blocks_2_conv2_conv_weight, ema_backbone_stage4_2_blocks_2_conv2_bn_weight, ema_backbone_stage4_2_blocks_2_conv2_bn_bias, ema_backbone_stage4_2_blocks_2_conv2_bn_running_mean, ema_backbone_stage4_2_blocks_2_conv2_bn_running_var, ema_backbone_stage4_2_blocks_2_conv2_bn_num_batches_tracked, ema_neck_reduce_layers_0_conv_weight, ema_neck_reduce_layers_0_bn_weight, ema_neck_reduce_layers_0_bn_bias, ema_neck_reduce_layers_0_bn_running_mean, ema_neck_reduce_layers_0_bn_running_var, ema_neck_reduce_layers_0_bn_num_batches_tracked, ema_neck_reduce_layers_1_conv_weight, ema_neck_reduce_layers_1_bn_weight, ema_neck_reduce_layers_1_bn_bias, ema_neck_reduce_layers_1_bn_running_mean, ema_neck_reduce_layers_1_bn_running_var, ema_neck_reduce_layers_1_bn_num_batches_tracked, ema_neck_top_down_blocks_0_main_conv_conv_weight, ema_neck_top_down_blocks_0_main_conv_bn_weight, ema_neck_top_down_blocks_0_main_conv_bn_bias, ema_neck_top_down_blocks_0_main_conv_bn_running_mean, ema_neck_top_down_blocks_0_main_conv_bn_running_var, ema_neck_top_down_blocks_0_main_conv_bn_num_batches_tracked, ema_neck_top_down_blocks_0_short_conv_conv_weight, ema_neck_top_down_blocks_0_short_conv_bn_weight, ema_neck_top_down_blocks_0_short_conv_bn_bias, ema_neck_top_down_blocks_0_short_conv_bn_running_mean, ema_neck_top_down_blocks_0_short_conv_bn_running_var, ema_neck_top_down_blocks_0_short_conv_bn_num_batches_tracked, ema_neck_top_down_blocks_0_final_conv_conv_weight, ema_neck_top_down_blocks_0_final_conv_bn_weight, ema_neck_top_down_blocks_0_final_conv_bn_bias, ema_neck_top_down_blocks_0_final_conv_bn_running_mean, ema_neck_top_down_blocks_0_final_conv_bn_running_var, ema_neck_top_down_blocks_0_final_conv_bn_num_batches_tracked, ema_neck_top_down_blocks_0_blocks_0_conv1_conv_weight, ema_neck_top_down_blocks_0_blocks_0_conv1_bn_weight, ema_neck_top_down_blocks_0_blocks_0_conv1_bn_bias, ema_neck_top_down_blocks_0_blocks_0_conv1_bn_running_mean, ema_neck_top_down_blocks_0_blocks_0_conv1_bn_running_var, ema_neck_top_down_blocks_0_blocks_0_conv1_bn_num_batches_tracked, ema_neck_top_down_blocks_0_blocks_0_conv2_conv_weight, ema_neck_top_down_blocks_0_blocks_0_conv2_bn_weight, ema_neck_top_down_blocks_0_blocks_0_conv2_bn_bias, ema_neck_top_down_blocks_0_blocks_0_conv2_bn_running_mean, ema_neck_top_down_blocks_0_blocks_0_conv2_bn_running_var, ema_neck_top_down_blocks_0_blocks_0_conv2_bn_num_batches_tracked, ema_neck_top_down_blocks_0_blocks_1_conv1_conv_weight, ema_neck_top_down_blocks_0_blocks_1_conv1_bn_weight, ema_neck_top_down_blocks_0_blocks_1_conv1_bn_bias, ema_neck_top_down_blocks_0_blocks_1_conv1_bn_running_mean, ema_neck_top_down_blocks_0_blocks_1_conv1_bn_running_var, ema_neck_top_down_blocks_0_blocks_1_conv1_bn_num_batches_tracked, ema_neck_top_down_blocks_0_blocks_1_conv2_conv_weight, ema_neck_top_down_blocks_0_blocks_1_conv2_bn_weight, ema_neck_top_down_blocks_0_blocks_1_conv2_bn_bias, ema_neck_top_down_blocks_0_blocks_1_conv2_bn_running_mean, ema_neck_top_down_blocks_0_blocks_1_conv2_bn_running_var, ema_neck_top_down_blocks_0_blocks_1_conv2_bn_num_batches_tracked, ema_neck_top_down_blocks_0_blocks_2_conv1_conv_weight, ema_neck_top_down_blocks_0_blocks_2_conv1_bn_weight, ema_neck_top_down_blocks_0_blocks_2_conv1_bn_bias, ema_neck_top_down_blocks_0_blocks_2_conv1_bn_running_mean, ema_neck_top_down_blocks_0_blocks_2_conv1_bn_running_var, ema_neck_top_down_blocks_0_blocks_2_conv1_bn_num_batches_tracked, ema_neck_top_down_blocks_0_blocks_2_conv2_conv_weight, ema_neck_top_down_blocks_0_blocks_2_conv2_bn_weight, ema_neck_top_down_blocks_0_blocks_2_conv2_bn_bias, ema_neck_top_down_blocks_0_blocks_2_conv2_bn_running_mean, ema_neck_top_down_blocks_0_blocks_2_conv2_bn_running_var, ema_neck_top_down_blocks_0_blocks_2_conv2_bn_num_batches_tracked, ema_neck_top_down_blocks_1_main_conv_conv_weight, ema_neck_top_down_blocks_1_main_conv_bn_weight, ema_neck_top_down_blocks_1_main_conv_bn_bias, ema_neck_top_down_blocks_1_main_conv_bn_running_mean, ema_neck_top_down_blocks_1_main_conv_bn_running_var, ema_neck_top_down_blocks_1_main_conv_bn_num_batches_tracked, ema_neck_top_down_blocks_1_short_conv_conv_weight, ema_neck_top_down_blocks_1_short_conv_bn_weight, ema_neck_top_down_blocks_1_short_conv_bn_bias, ema_neck_top_down_blocks_1_short_conv_bn_running_mean, ema_neck_top_down_blocks_1_short_conv_bn_running_var, ema_neck_top_down_blocks_1_short_conv_bn_num_batches_tracked, ema_neck_top_down_blocks_1_final_conv_conv_weight, ema_neck_top_down_blocks_1_final_conv_bn_weight, ema_neck_top_down_blocks_1_final_conv_bn_bias, ema_neck_top_down_blocks_1_final_conv_bn_running_mean, ema_neck_top_down_blocks_1_final_conv_bn_running_var, ema_neck_top_down_blocks_1_final_conv_bn_num_batches_tracked, ema_neck_top_down_blocks_1_blocks_0_conv1_conv_weight, ema_neck_top_down_blocks_1_blocks_0_conv1_bn_weight, ema_neck_top_down_blocks_1_blocks_0_conv1_bn_bias, ema_neck_top_down_blocks_1_blocks_0_conv1_bn_running_mean, ema_neck_top_down_blocks_1_blocks_0_conv1_bn_running_var, ema_neck_top_down_blocks_1_blocks_0_conv1_bn_num_batches_tracked, ema_neck_top_down_blocks_1_blocks_0_conv2_conv_weight, ema_neck_top_down_blocks_1_blocks_0_conv2_bn_weight, ema_neck_top_down_blocks_1_blocks_0_conv2_bn_bias, ema_neck_top_down_blocks_1_blocks_0_conv2_bn_running_mean, ema_neck_top_down_blocks_1_blocks_0_conv2_bn_running_var, ema_neck_top_down_blocks_1_blocks_0_conv2_bn_num_batches_tracked, ema_neck_top_down_blocks_1_blocks_1_conv1_conv_weight, ema_neck_top_down_blocks_1_blocks_1_conv1_bn_weight, ema_neck_top_down_blocks_1_blocks_1_conv1_bn_bias, ema_neck_top_down_blocks_1_blocks_1_conv1_bn_running_mean, ema_neck_top_down_blocks_1_blocks_1_conv1_bn_running_var, ema_neck_top_down_blocks_1_blocks_1_conv1_bn_num_batches_tracked, ema_neck_top_down_blocks_1_blocks_1_conv2_conv_weight, ema_neck_top_down_blocks_1_blocks_1_conv2_bn_weight, ema_neck_top_down_blocks_1_blocks_1_conv2_bn_bias, ema_neck_top_down_blocks_1_blocks_1_conv2_bn_running_mean, ema_neck_top_down_blocks_1_blocks_1_conv2_bn_running_var, ema_neck_top_down_blocks_1_blocks_1_conv2_bn_num_batches_tracked, ema_neck_top_down_blocks_1_blocks_2_conv1_conv_weight, ema_neck_top_down_blocks_1_blocks_2_conv1_bn_weight, ema_neck_top_down_blocks_1_blocks_2_conv1_bn_bias, ema_neck_top_down_blocks_1_blocks_2_conv1_bn_running_mean, ema_neck_top_down_blocks_1_blocks_2_conv1_bn_running_var, ema_neck_top_down_blocks_1_blocks_2_conv1_bn_num_batches_tracked, ema_neck_top_down_blocks_1_blocks_2_conv2_conv_weight, ema_neck_top_down_blocks_1_blocks_2_conv2_bn_weight, ema_neck_top_down_blocks_1_blocks_2_conv2_bn_bias, ema_neck_top_down_blocks_1_blocks_2_conv2_bn_running_mean, ema_neck_top_down_blocks_1_blocks_2_conv2_bn_running_var, ema_neck_top_down_blocks_1_blocks_2_conv2_bn_num_batches_tracked, ema_neck_downsamples_0_conv_weight, ema_neck_downsamples_0_bn_weight, ema_neck_downsamples_0_bn_bias, ema_neck_downsamples_0_bn_running_mean, ema_neck_downsamples_0_bn_running_var, ema_neck_downsamples_0_bn_num_batches_tracked, ema_neck_downsamples_1_conv_weight, ema_neck_downsamples_1_bn_weight, ema_neck_downsamples_1_bn_bias, ema_neck_downsamples_1_bn_running_mean, ema_neck_downsamples_1_bn_running_var, ema_neck_downsamples_1_bn_num_batches_tracked, ema_neck_bottom_up_blocks_0_main_conv_conv_weight, ema_neck_bottom_up_blocks_0_main_conv_bn_weight, ema_neck_bottom_up_blocks_0_main_conv_bn_bias, ema_neck_bottom_up_blocks_0_main_conv_bn_running_mean, ema_neck_bottom_up_blocks_0_main_conv_bn_running_var, ema_neck_bottom_up_blocks_0_main_conv_bn_num_batches_tracked, ema_neck_bottom_up_blocks_0_short_conv_conv_weight, ema_neck_bottom_up_blocks_0_short_conv_bn_weight, ema_neck_bottom_up_blocks_0_short_conv_bn_bias, ema_neck_bottom_up_blocks_0_short_conv_bn_running_mean, ema_neck_bottom_up_blocks_0_short_conv_bn_running_var, ema_neck_bottom_up_blocks_0_short_conv_bn_num_batches_tracked, ema_neck_bottom_up_blocks_0_final_conv_conv_weight, ema_neck_bottom_up_blocks_0_final_conv_bn_weight, ema_neck_bottom_up_blocks_0_final_conv_bn_bias, ema_neck_bottom_up_blocks_0_final_conv_bn_running_mean, ema_neck_bottom_up_blocks_0_final_conv_bn_running_var, ema_neck_bottom_up_blocks_0_final_conv_bn_num_batches_tracked, ema_neck_bottom_up_blocks_0_blocks_0_conv1_conv_weight, ema_neck_bottom_up_blocks_0_blocks_0_conv1_bn_weight, ema_neck_bottom_up_blocks_0_blocks_0_conv1_bn_bias, ema_neck_bottom_up_blocks_0_blocks_0_conv1_bn_running_mean, ema_neck_bottom_up_blocks_0_blocks_0_conv1_bn_running_var, ema_neck_bottom_up_blocks_0_blocks_0_conv1_bn_num_batches_tracked, ema_neck_bottom_up_blocks_0_blocks_0_conv2_conv_weight, ema_neck_bottom_up_blocks_0_blocks_0_conv2_bn_weight, ema_neck_bottom_up_blocks_0_blocks_0_conv2_bn_bias, ema_neck_bottom_up_blocks_0_blocks_0_conv2_bn_running_mean, ema_neck_bottom_up_blocks_0_blocks_0_conv2_bn_running_var, ema_neck_bottom_up_blocks_0_blocks_0_conv2_bn_num_batches_tracked, ema_neck_bottom_up_blocks_0_blocks_1_conv1_conv_weight, ema_neck_bottom_up_blocks_0_blocks_1_conv1_bn_weight, ema_neck_bottom_up_blocks_0_blocks_1_conv1_bn_bias, ema_neck_bottom_up_blocks_0_blocks_1_conv1_bn_running_mean, ema_neck_bottom_up_blocks_0_blocks_1_conv1_bn_running_var, ema_neck_bottom_up_blocks_0_blocks_1_conv1_bn_num_batches_tracked, ema_neck_bottom_up_blocks_0_blocks_1_conv2_conv_weight, ema_neck_bottom_up_blocks_0_blocks_1_conv2_bn_weight, ema_neck_bottom_up_blocks_0_blocks_1_conv2_bn_bias, ema_neck_bottom_up_blocks_0_blocks_1_conv2_bn_running_mean, ema_neck_bottom_up_blocks_0_blocks_1_conv2_bn_running_var, ema_neck_bottom_up_blocks_0_blocks_1_conv2_bn_num_batches_tracked, ema_neck_bottom_up_blocks_0_blocks_2_conv1_conv_weight, ema_neck_bottom_up_blocks_0_blocks_2_conv1_bn_weight, ema_neck_bottom_up_blocks_0_blocks_2_conv1_bn_bias, ema_neck_bottom_up_blocks_0_blocks_2_conv1_bn_running_mean, ema_neck_bottom_up_blocks_0_blocks_2_conv1_bn_running_var, ema_neck_bottom_up_blocks_0_blocks_2_conv1_bn_num_batches_tracked, ema_neck_bottom_up_blocks_0_blocks_2_conv2_conv_weight, ema_neck_bottom_up_blocks_0_blocks_2_conv2_bn_weight, ema_neck_bottom_up_blocks_0_blocks_2_conv2_bn_bias, ema_neck_bottom_up_blocks_0_blocks_2_conv2_bn_running_mean, ema_neck_bottom_up_blocks_0_blocks_2_conv2_bn_running_var, ema_neck_bottom_up_blocks_0_blocks_2_conv2_bn_num_batches_tracked, ema_neck_bottom_up_blocks_1_main_conv_conv_weight, ema_neck_bottom_up_blocks_1_main_conv_bn_weight, ema_neck_bottom_up_blocks_1_main_conv_bn_bias, ema_neck_bottom_up_blocks_1_main_conv_bn_running_mean, ema_neck_bottom_up_blocks_1_main_conv_bn_running_var, ema_neck_bottom_up_blocks_1_main_conv_bn_num_batches_tracked, ema_neck_bottom_up_blocks_1_short_conv_conv_weight, ema_neck_bottom_up_blocks_1_short_conv_bn_weight, ema_neck_bottom_up_blocks_1_short_conv_bn_bias, ema_neck_bottom_up_blocks_1_short_conv_bn_running_mean, ema_neck_bottom_up_blocks_1_short_conv_bn_running_var, ema_neck_bottom_up_blocks_1_short_conv_bn_num_batches_tracked, ema_neck_bottom_up_blocks_1_final_conv_conv_weight, ema_neck_bottom_up_blocks_1_final_conv_bn_weight, ema_neck_bottom_up_blocks_1_final_conv_bn_bias, ema_neck_bottom_up_blocks_1_final_conv_bn_running_mean, ema_neck_bottom_up_blocks_1_final_conv_bn_running_var, ema_neck_bottom_up_blocks_1_final_conv_bn_num_batches_tracked, ema_neck_bottom_up_blocks_1_blocks_0_conv1_conv_weight, ema_neck_bottom_up_blocks_1_blocks_0_conv1_bn_weight, ema_neck_bottom_up_blocks_1_blocks_0_conv1_bn_bias, ema_neck_bottom_up_blocks_1_blocks_0_conv1_bn_running_mean, ema_neck_bottom_up_blocks_1_blocks_0_conv1_bn_running_var, ema_neck_bottom_up_blocks_1_blocks_0_conv1_bn_num_batches_tracked, ema_neck_bottom_up_blocks_1_blocks_0_conv2_conv_weight, ema_neck_bottom_up_blocks_1_blocks_0_conv2_bn_weight, ema_neck_bottom_up_blocks_1_blocks_0_conv2_bn_bias, ema_neck_bottom_up_blocks_1_blocks_0_conv2_bn_running_mean, ema_neck_bottom_up_blocks_1_blocks_0_conv2_bn_running_var, ema_neck_bottom_up_blocks_1_blocks_0_conv2_bn_num_batches_tracked, ema_neck_bottom_up_blocks_1_blocks_1_conv1_conv_weight, ema_neck_bottom_up_blocks_1_blocks_1_conv1_bn_weight, ema_neck_bottom_up_blocks_1_blocks_1_conv1_bn_bias, ema_neck_bottom_up_blocks_1_blocks_1_conv1_bn_running_mean, ema_neck_bottom_up_blocks_1_blocks_1_conv1_bn_running_var, ema_neck_bottom_up_blocks_1_blocks_1_conv1_bn_num_batches_tracked, ema_neck_bottom_up_blocks_1_blocks_1_conv2_conv_weight, ema_neck_bottom_up_blocks_1_blocks_1_conv2_bn_weight, ema_neck_bottom_up_blocks_1_blocks_1_conv2_bn_bias, ema_neck_bottom_up_blocks_1_blocks_1_conv2_bn_running_mean, ema_neck_bottom_up_blocks_1_blocks_1_conv2_bn_running_var, ema_neck_bottom_up_blocks_1_blocks_1_conv2_bn_num_batches_tracked, ema_neck_bottom_up_blocks_1_blocks_2_conv1_conv_weight, ema_neck_bottom_up_blocks_1_blocks_2_conv1_bn_weight, ema_neck_bottom_up_blocks_1_blocks_2_conv1_bn_bias, ema_neck_bottom_up_blocks_1_blocks_2_conv1_bn_running_mean, ema_neck_bottom_up_blocks_1_blocks_2_conv1_bn_running_var, ema_neck_bottom_up_blocks_1_blocks_2_conv1_bn_num_batches_tracked, ema_neck_bottom_up_blocks_1_blocks_2_conv2_conv_weight, ema_neck_bottom_up_blocks_1_blocks_2_conv2_bn_weight, ema_neck_bottom_up_blocks_1_blocks_2_conv2_bn_bias, ema_neck_bottom_up_blocks_1_blocks_2_conv2_bn_running_mean, ema_neck_bottom_up_blocks_1_blocks_2_conv2_bn_running_var, ema_neck_bottom_up_blocks_1_blocks_2_conv2_bn_num_batches_tracked, ema_neck_out_convs_0_conv_weight, ema_neck_out_convs_0_bn_weight, ema_neck_out_convs_0_bn_bias, ema_neck_out_convs_0_bn_running_mean, ema_neck_out_convs_0_bn_running_var, ema_neck_out_convs_0_bn_num_batches_tracked, ema_neck_out_convs_1_conv_weight, ema_neck_out_convs_1_bn_weight, ema_neck_out_convs_1_bn_bias, ema_neck_out_convs_1_bn_running_mean, ema_neck_out_convs_1_bn_running_var, ema_neck_out_convs_1_bn_num_batches_tracked, ema_neck_out_convs_2_conv_weight, ema_neck_out_convs_2_bn_weight, ema_neck_out_convs_2_bn_bias, ema_neck_out_convs_2_bn_running_mean, ema_neck_out_convs_2_bn_running_var, ema_neck_out_convs_2_bn_num_batches_tracked, ema_bbox_head_multi_level_cls_convs_0_0_conv_weight, ema_bbox_head_multi_level_cls_convs_0_0_bn_weight, ema_bbox_head_multi_level_cls_convs_0_0_bn_bias, ema_bbox_head_multi_level_cls_convs_0_0_bn_running_mean, ema_bbox_head_multi_level_cls_convs_0_0_bn_running_var, ema_bbox_head_multi_level_cls_convs_0_0_bn_num_batches_tracked, ema_bbox_head_multi_level_cls_convs_0_1_conv_weight, ema_bbox_head_multi_level_cls_convs_0_1_bn_weight, ema_bbox_head_multi_level_cls_convs_0_1_bn_bias, ema_bbox_head_multi_level_cls_convs_0_1_bn_running_mean, ema_bbox_head_multi_level_cls_convs_0_1_bn_running_var, ema_bbox_head_multi_level_cls_convs_0_1_bn_num_batches_tracked, ema_bbox_head_multi_level_cls_convs_1_0_conv_weight, ema_bbox_head_multi_level_cls_convs_1_0_bn_weight, ema_bbox_head_multi_level_cls_convs_1_0_bn_bias, ema_bbox_head_multi_level_cls_convs_1_0_bn_running_mean, ema_bbox_head_multi_level_cls_convs_1_0_bn_running_var, ema_bbox_head_multi_level_cls_convs_1_0_bn_num_batches_tracked, ema_bbox_head_multi_level_cls_convs_1_1_conv_weight, ema_bbox_head_multi_level_cls_convs_1_1_bn_weight, ema_bbox_head_multi_level_cls_convs_1_1_bn_bias, ema_bbox_head_multi_level_cls_convs_1_1_bn_running_mean, ema_bbox_head_multi_level_cls_convs_1_1_bn_running_var, ema_bbox_head_multi_level_cls_convs_1_1_bn_num_batches_tracked, ema_bbox_head_multi_level_cls_convs_2_0_conv_weight, ema_bbox_head_multi_level_cls_convs_2_0_bn_weight, ema_bbox_head_multi_level_cls_convs_2_0_bn_bias, ema_bbox_head_multi_level_cls_convs_2_0_bn_running_mean, ema_bbox_head_multi_level_cls_convs_2_0_bn_running_var, ema_bbox_head_multi_level_cls_convs_2_0_bn_num_batches_tracked, ema_bbox_head_multi_level_cls_convs_2_1_conv_weight, ema_bbox_head_multi_level_cls_convs_2_1_bn_weight, ema_bbox_head_multi_level_cls_convs_2_1_bn_bias, ema_bbox_head_multi_level_cls_convs_2_1_bn_running_mean, ema_bbox_head_multi_level_cls_convs_2_1_bn_running_var, ema_bbox_head_multi_level_cls_convs_2_1_bn_num_batches_tracked, ema_bbox_head_multi_level_reg_convs_0_0_conv_weight, ema_bbox_head_multi_level_reg_convs_0_0_bn_weight, ema_bbox_head_multi_level_reg_convs_0_0_bn_bias, ema_bbox_head_multi_level_reg_convs_0_0_bn_running_mean, ema_bbox_head_multi_level_reg_convs_0_0_bn_running_var, ema_bbox_head_multi_level_reg_convs_0_0_bn_num_batches_tracked, ema_bbox_head_multi_level_reg_convs_0_1_conv_weight, ema_bbox_head_multi_level_reg_convs_0_1_bn_weight, ema_bbox_head_multi_level_reg_convs_0_1_bn_bias, ema_bbox_head_multi_level_reg_convs_0_1_bn_running_mean, ema_bbox_head_multi_level_reg_convs_0_1_bn_running_var, ema_bbox_head_multi_level_reg_convs_0_1_bn_num_batches_tracked, ema_bbox_head_multi_level_reg_convs_1_0_conv_weight, ema_bbox_head_multi_level_reg_convs_1_0_bn_weight, ema_bbox_head_multi_level_reg_convs_1_0_bn_bias, ema_bbox_head_multi_level_reg_convs_1_0_bn_running_mean, ema_bbox_head_multi_level_reg_convs_1_0_bn_running_var, ema_bbox_head_multi_level_reg_convs_1_0_bn_num_batches_tracked, ema_bbox_head_multi_level_reg_convs_1_1_conv_weight, ema_bbox_head_multi_level_reg_convs_1_1_bn_weight, ema_bbox_head_multi_level_reg_convs_1_1_bn_bias, ema_bbox_head_multi_level_reg_convs_1_1_bn_running_mean, ema_bbox_head_multi_level_reg_convs_1_1_bn_running_var, ema_bbox_head_multi_level_reg_convs_1_1_bn_num_batches_tracked, ema_bbox_head_multi_level_reg_convs_2_0_conv_weight, ema_bbox_head_multi_level_reg_convs_2_0_bn_weight, ema_bbox_head_multi_level_reg_convs_2_0_bn_bias, ema_bbox_head_multi_level_reg_convs_2_0_bn_running_mean, ema_bbox_head_multi_level_reg_convs_2_0_bn_running_var, ema_bbox_head_multi_level_reg_convs_2_0_bn_num_batches_tracked, ema_bbox_head_multi_level_reg_convs_2_1_conv_weight, ema_bbox_head_multi_level_reg_convs_2_1_bn_weight, ema_bbox_head_multi_level_reg_convs_2_1_bn_bias, ema_bbox_head_multi_level_reg_convs_2_1_bn_running_mean, ema_bbox_head_multi_level_reg_convs_2_1_bn_running_var, ema_bbox_head_multi_level_reg_convs_2_1_bn_num_batches_tracked, ema_bbox_head_multi_level_conv_cls_0_weight, ema_bbox_head_multi_level_conv_cls_0_bias, ema_bbox_head_multi_level_conv_cls_1_weight, ema_bbox_head_multi_level_conv_cls_1_bias, ema_bbox_head_multi_level_conv_cls_2_weight, ema_bbox_head_multi_level_conv_cls_2_bias, ema_bbox_head_multi_level_conv_reg_0_weight, ema_bbox_head_multi_level_conv_reg_0_bias, ema_bbox_head_multi_level_conv_reg_1_weight, ema_bbox_head_multi_level_conv_reg_1_bias, ema_bbox_head_multi_level_conv_reg_2_weight, ema_bbox_head_multi_level_conv_reg_2_bias, ema_bbox_head_multi_level_conv_obj_0_weight, ema_bbox_head_multi_level_conv_obj_0_bias, ema_bbox_head_multi_level_conv_obj_1_weight, ema_bbox_head_multi_level_conv_obj_1_bias, ema_bbox_head_multi_level_conv_obj_2_weight, ema_bbox_head_multi_level_conv_obj_2_bias

2022-07-13 19:09:04,216 - mmdet - INFO - resumed epoch 280, iter 46480
2022-07-13 19:09:04,217 - mmdet - INFO - Start running, host: naama@naama1230u, work_dir: /home/naama/Documents/MyProjects/ml_projects/ml_detection/ml_detection/work_dirs/yolox_l_8x8_300e_coco_airbus
2022-07-13 19:09:04,218 - mmdet - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) YOLOXLrUpdaterHook                 
(49          ) ExpMomentumEMAHook                 
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) YOLOXLrUpdaterHook                 
(48          ) YOLOXModeSwitchHook                
(48          ) SyncNormHook                       
(49          ) ExpMomentumEMAHook                 
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_train_iter:
(VERY_HIGH   ) YOLOXLrUpdaterHook                 
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(49          ) ExpMomentumEMAHook                 
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
after_train_epoch:
(48          ) SyncNormHook                       
(49          ) ExpMomentumEMAHook                 
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
2022-07-13 19:09:04,218 - mmdet - INFO - workflow: [('train', 1)], max: 300 epochs
2022-07-13 19:09:04,228 - mmdet - INFO - Checkpoints will be saved to /home/naama/Documents/MyProjects/ml_projects/ml_detection/ml_detection/work_dirs/yolox_l_8x8_300e_coco_airbus by HardDiskBackend.
2022-07-13 19:09:11,325 - mmdet - INFO - Epoch [281][10/166]	lr: 5.073e-04, eta: 0:38:57, time: 0.706, data_time: 0.274, memory: 12154, loss_cls: 0.3941, loss_bbox: 1.2811, loss_obj: 0.6282, loss: 2.3035
2022-07-13 19:09:15,880 - mmdet - INFO - Epoch [281][20/166]	lr: 5.071e-04, eta: 0:31:56, time: 0.455, data_time: 0.007, memory: 12154, loss_cls: 0.4054, loss_bbox: 1.3462, loss_obj: 0.5995, loss: 2.3511
2022-07-13 19:09:20,243 - mmdet - INFO - Epoch [281][30/166]	lr: 5.069e-04, eta: 0:29:12, time: 0.436, data_time: 0.007, memory: 17027, loss_cls: 0.4005, loss_bbox: 1.3079, loss_obj: 0.5859, loss: 2.2944
2022-07-13 19:09:24,322 - mmdet - INFO - Epoch [281][40/166]	lr: 5.068e-04, eta: 0:27:24, time: 0.408, data_time: 0.007, memory: 17027, loss_cls: 0.4125, loss_bbox: 1.3727, loss_obj: 0.6101, loss: 2.3953
2022-07-13 19:09:26,936 - mmdet - INFO - Epoch [281][50/166]	lr: 5.066e-04, eta: 0:24:42, time: 0.261, data_time: 0.008, memory: 17027, loss_cls: 0.3945, loss_bbox: 1.2809, loss_obj: 0.6207, loss: 2.2962
2022-07-13 19:09:31,167 - mmdet - INFO - Epoch [281][60/166]	lr: 5.064e-04, eta: 0:24:21, time: 0.423, data_time: 0.007, memory: 17051, loss_cls: 0.4232, loss_bbox: 1.4160, loss_obj: 0.7180, loss: 2.5573
2022-07-13 19:09:34,473 - mmdet - INFO - Epoch [281][70/166]	lr: 5.063e-04, eta: 0:23:22, time: 0.330, data_time: 0.007, memory: 17051, loss_cls: 0.4096, loss_bbox: 1.3705, loss_obj: 0.7294, loss: 2.5095
2022-07-13 19:09:39,855 - mmdet - INFO - Epoch [281][80/166]	lr: 5.061e-04, eta: 0:24:01, time: 0.538, data_time: 0.014, memory: 17051, loss_cls: 0.3904, loss_bbox: 1.2562, loss_obj: 0.5846, loss: 2.2311
2022-07-13 19:09:42,262 - mmdet - INFO - Epoch [281][90/166]	lr: 5.059e-04, eta: 0:22:43, time: 0.241, data_time: 0.008, memory: 17051, loss_cls: 0.4052, loss_bbox: 1.3384, loss_obj: 0.6135, loss: 2.3571
2022-07-13 19:09:44,974 - mmdet - INFO - Epoch [281][100/166]	lr: 5.058e-04, eta: 0:21:50, time: 0.271, data_time: 0.008, memory: 17051, loss_cls: 0.3985, loss_bbox: 1.3164, loss_obj: 0.6069, loss: 2.3218
2022-07-13 19:09:49,742 - mmdet - INFO - Epoch [281][110/166]	lr: 5.056e-04, eta: 0:22:07, time: 0.477, data_time: 0.007, memory: 18400, loss_cls: 0.3839, loss_bbox: 1.2319, loss_obj: 0.6252, loss: 2.2409
2022-07-13 19:09:53,267 - mmdet - INFO - Epoch [281][120/166]	lr: 5.055e-04, eta: 0:21:46, time: 0.352, data_time: 0.007, memory: 18400, loss_cls: 0.4080, loss_bbox: 1.3557, loss_obj: 0.7151, loss: 2.4788
2022-07-13 19:09:56,172 - mmdet - INFO - Epoch [281][130/166]	lr: 5.053e-04, eta: 0:21:13, time: 0.290, data_time: 0.008, memory: 18400, loss_cls: 0.4006, loss_bbox: 1.3230, loss_obj: 0.6054, loss: 2.3290
2022-07-13 19:09:59,176 - mmdet - INFO - Epoch [281][140/166]	lr: 5.052e-04, eta: 0:20:47, time: 0.300, data_time: 0.007, memory: 18400, loss_cls: 0.3898, loss_bbox: 1.2651, loss_obj: 0.6274, loss: 2.2823
2022-07-13 19:10:02,188 - mmdet - INFO - Epoch [281][150/166]	lr: 5.050e-04, eta: 0:20:24, time: 0.301, data_time: 0.008, memory: 18400, loss_cls: 0.3984, loss_bbox: 1.3187, loss_obj: 0.6270, loss: 2.3441
2022-07-13 19:10:06,455 - mmdet - INFO - Epoch [281][160/166]	lr: 5.049e-04, eta: 0:20:28, time: 0.427, data_time: 0.007, memory: 18400, loss_cls: 0.4013, loss_bbox: 1.3125, loss_obj: 0.6673, loss: 2.3811
2022-07-13 19:10:14,349 - mmdet - INFO - Epoch [282][10/166]	lr: 5.046e-04, eta: 0:20:21, time: 0.617, data_time: 0.247, memory: 18400, loss_cls: 0.3990, loss_bbox: 1.3033, loss_obj: 0.6368, loss: 2.3391
2022-07-13 19:10:19,258 - mmdet - INFO - Epoch [282][20/166]	lr: 5.045e-04, eta: 0:20:34, time: 0.491, data_time: 0.017, memory: 18400, loss_cls: 0.3924, loss_bbox: 1.2683, loss_obj: 0.5923, loss: 2.2531
2022-07-13 19:10:24,086 - mmdet - INFO - Epoch [282][30/166]	lr: 5.044e-04, eta: 0:20:44, time: 0.483, data_time: 0.016, memory: 18400, loss_cls: 0.3941, loss_bbox: 1.2630, loss_obj: 0.5742, loss: 2.2312
2022-07-13 19:10:27,078 - mmdet - INFO - Epoch [282][40/166]	lr: 5.042e-04, eta: 0:20:25, time: 0.299, data_time: 0.008, memory: 18400, loss_cls: 0.4036, loss_bbox: 1.3329, loss_obj: 0.6488, loss: 2.3853
2022-07-13 19:10:30,394 - mmdet - INFO - Epoch [282][50/166]	lr: 5.041e-04, eta: 0:20:12, time: 0.332, data_time: 0.008, memory: 18400, loss_cls: 0.4027, loss_bbox: 1.3212, loss_obj: 0.5895, loss: 2.3134
2022-07-13 19:10:34,674 - mmdet - INFO - Epoch [282][60/166]	lr: 5.040e-04, eta: 0:20:14, time: 0.428, data_time: 0.016, memory: 18400, loss_cls: 0.4017, loss_bbox: 1.3121, loss_obj: 0.6356, loss: 2.3494
2022-07-13 19:10:38,129 - mmdet - INFO - Epoch [282][70/166]	lr: 5.038e-04, eta: 0:20:04, time: 0.345, data_time: 0.007, memory: 18400, loss_cls: 0.4036, loss_bbox: 1.3274, loss_obj: 0.5950, loss: 2.3260
2022-07-13 19:10:42,160 - mmdet - INFO - Epoch [282][80/166]	lr: 5.037e-04, eta: 0:20:01, time: 0.403, data_time: 0.007, memory: 18400, loss_cls: 0.3962, loss_bbox: 1.2949, loss_obj: 0.6154, loss: 2.3064
2022-07-13 19:10:45,350 - mmdet - INFO - Epoch [282][90/166]	lr: 5.036e-04, eta: 0:19:49, time: 0.319, data_time: 0.007, memory: 18400, loss_cls: 0.4072, loss_bbox: 1.3374, loss_obj: 0.6272, loss: 2.3718
2022-07-13 19:10:47,786 - mmdet - INFO - Epoch [282][100/166]	lr: 5.035e-04, eta: 0:19:28, time: 0.244, data_time: 0.008, memory: 18400, loss_cls: 0.4087, loss_bbox: 1.3548, loss_obj: 0.6240, loss: 2.3874
2022-07-13 19:10:51,099 - mmdet - INFO - Epoch [282][110/166]	lr: 5.033e-04, eta: 0:19:19, time: 0.331, data_time: 0.007, memory: 18400, loss_cls: 0.3956, loss_bbox: 1.3119, loss_obj: 0.7211, loss: 2.4286
2022-07-13 19:10:54,628 - mmdet - INFO - Epoch [282][120/166]	lr: 5.032e-04, eta: 0:19:12, time: 0.353, data_time: 0.007, memory: 18400, loss_cls: 0.3974, loss_bbox: 1.3013, loss_obj: 0.6386, loss: 2.3373
2022-07-13 19:10:58,486 - mmdet - INFO - Epoch [282][130/166]	lr: 5.031e-04, eta: 0:19:09, time: 0.386, data_time: 0.007, memory: 18400, loss_cls: 0.3812, loss_bbox: 1.2106, loss_obj: 0.5356, loss: 2.1274
2022-07-13 19:11:01,794 - mmdet - INFO - Epoch [282][140/166]	lr: 5.030e-04, eta: 0:19:00, time: 0.331, data_time: 0.008, memory: 18400, loss_cls: 0.4138, loss_bbox: 1.3666, loss_obj: 0.5707, loss: 2.3512
2022-07-13 19:11:04,143 - mmdet - INFO - Epoch [282][150/166]	lr: 5.029e-04, eta: 0:18:43, time: 0.235, data_time: 0.008, memory: 18400, loss_cls: 0.4069, loss_bbox: 1.3587, loss_obj: 0.6644, loss: 2.4300
2022-07-13 19:11:06,795 - mmdet - INFO - Epoch [282][160/166]	lr: 5.028e-04, eta: 0:18:29, time: 0.265, data_time: 0.007, memory: 18400, loss_cls: 0.4162, loss_bbox: 1.4050, loss_obj: 0.6834, loss: 2.5046
2022-07-13 19:11:15,174 - mmdet - INFO - Epoch [283][10/166]	lr: 5.026e-04, eta: 0:18:26, time: 0.632, data_time: 0.249, memory: 18400, loss_cls: 0.4040, loss_bbox: 1.3270, loss_obj: 0.5945, loss: 2.3256
2022-07-13 19:11:17,585 - mmdet - INFO - Epoch [283][20/166]	lr: 5.025e-04, eta: 0:18:12, time: 0.241, data_time: 0.008, memory: 18400, loss_cls: 0.4081, loss_bbox: 1.3533, loss_obj: 0.6840, loss: 2.4455
2022-07-13 19:11:20,686 - mmdet - INFO - Epoch [283][30/166]	lr: 5.024e-04, eta: 0:18:03, time: 0.310, data_time: 0.007, memory: 18400, loss_cls: 0.4011, loss_bbox: 1.3266, loss_obj: 0.6278, loss: 2.3556
2022-07-13 19:11:24,325 - mmdet - INFO - Epoch [283][40/166]	lr: 5.023e-04, eta: 0:17:59, time: 0.364, data_time: 0.007, memory: 18400, loss_cls: 0.4089, loss_bbox: 1.3529, loss_obj: 0.6691, loss: 2.4309
2022-07-13 19:11:26,478 - mmdet - INFO - Epoch [283][50/166]	lr: 5.022e-04, eta: 0:17:44, time: 0.215, data_time: 0.008, memory: 18400, loss_cls: 0.4207, loss_bbox: 1.4403, loss_obj: 0.6833, loss: 2.5443
2022-07-13 19:11:28,632 - mmdet - INFO - Epoch [283][60/166]	lr: 5.021e-04, eta: 0:17:29, time: 0.215, data_time: 0.008, memory: 18400, loss_cls: 0.4094, loss_bbox: 1.3570, loss_obj: 0.6186, loss: 2.3850
2022-07-13 19:11:31,285 - mmdet - INFO - Epoch [283][70/166]	lr: 5.020e-04, eta: 0:17:19, time: 0.265, data_time: 0.008, memory: 18400, loss_cls: 0.4097, loss_bbox: 1.3717, loss_obj: 0.6478, loss: 2.4293
2022-07-13 19:11:35,701 - mmdet - INFO - Epoch [283][80/166]	lr: 5.019e-04, eta: 0:17:22, time: 0.442, data_time: 0.007, memory: 18400, loss_cls: 0.4164, loss_bbox: 1.3811, loss_obj: 0.6314, loss: 2.4289
2022-07-13 19:11:39,037 - mmdet - INFO - Epoch [283][90/166]	lr: 5.018e-04, eta: 0:17:16, time: 0.334, data_time: 0.007, memory: 18400, loss_cls: 0.4020, loss_bbox: 1.3146, loss_obj: 0.7099, loss: 2.4264
2022-07-13 19:11:42,038 - mmdet - INFO - Epoch [283][100/166]	lr: 5.017e-04, eta: 0:17:09, time: 0.300, data_time: 0.008, memory: 18400, loss_cls: 0.4041, loss_bbox: 1.3426, loss_obj: 0.6497, loss: 2.3964
2022-07-13 19:11:46,126 - mmdet - INFO - Epoch [283][110/166]	lr: 5.016e-04, eta: 0:17:09, time: 0.409, data_time: 0.007, memory: 18400, loss_cls: 0.3896, loss_bbox: 1.2545, loss_obj: 0.6264, loss: 2.2704
2022-07-13 19:11:49,297 - mmdet - INFO - Epoch [283][120/166]	lr: 5.016e-04, eta: 0:17:03, time: 0.317, data_time: 0.007, memory: 18400, loss_cls: 0.4045, loss_bbox: 1.3209, loss_obj: 0.6266, loss: 2.3519
2022-07-13 19:11:52,283 - mmdet - INFO - Epoch [283][130/166]	lr: 5.015e-04, eta: 0:16:55, time: 0.298, data_time: 0.008, memory: 18400, loss_cls: 0.4058, loss_bbox: 1.3526, loss_obj: 0.6339, loss: 2.3924
2022-07-13 19:11:55,623 - mmdet - INFO - Epoch [283][140/166]	lr: 5.014e-04, eta: 0:16:51, time: 0.334, data_time: 0.007, memory: 18400, loss_cls: 0.4050, loss_bbox: 1.3378, loss_obj: 0.6073, loss: 2.3501
2022-07-13 19:11:59,051 - mmdet - INFO - Epoch [283][150/166]	lr: 5.013e-04, eta: 0:16:46, time: 0.343, data_time: 0.007, memory: 18400, loss_cls: 0.4111, loss_bbox: 1.3650, loss_obj: 0.6055, loss: 2.3816
2022-07-13 19:12:01,637 - mmdet - INFO - Epoch [283][160/166]	lr: 5.012e-04, eta: 0:16:37, time: 0.259, data_time: 0.008, memory: 18400, loss_cls: 0.3927, loss_bbox: 1.2818, loss_obj: 0.6684, loss: 2.3428
2022-07-13 19:12:09,637 - mmdet - INFO - Epoch [284][10/166]	lr: 5.011e-04, eta: 0:16:30, time: 0.542, data_time: 0.249, memory: 18400, loss_cls: 0.4012, loss_bbox: 1.3267, loss_obj: 0.6026, loss: 2.3304
2022-07-13 19:12:11,887 - mmdet - INFO - Epoch [284][20/166]	lr: 5.011e-04, eta: 0:16:20, time: 0.225, data_time: 0.008, memory: 18400, loss_cls: 0.4164, loss_bbox: 1.4078, loss_obj: 0.6891, loss: 2.5133
2022-07-13 19:12:14,895 - mmdet - INFO - Epoch [284][30/166]	lr: 5.010e-04, eta: 0:16:14, time: 0.301, data_time: 0.007, memory: 18400, loss_cls: 0.3975, loss_bbox: 1.2982, loss_obj: 0.5853, loss: 2.2810
2022-07-13 19:12:17,660 - mmdet - INFO - Epoch [284][40/166]	lr: 5.009e-04, eta: 0:16:07, time: 0.277, data_time: 0.008, memory: 18400, loss_cls: 0.4012, loss_bbox: 1.3328, loss_obj: 0.6106, loss: 2.3446
2022-07-13 19:12:20,510 - mmdet - INFO - Epoch [284][50/166]	lr: 5.009e-04, eta: 0:16:00, time: 0.285, data_time: 0.008, memory: 18400, loss_cls: 0.3900, loss_bbox: 1.2703, loss_obj: 0.6050, loss: 2.2653
2022-07-13 19:12:23,671 - mmdet - INFO - Epoch [284][60/166]	lr: 5.008e-04, eta: 0:15:55, time: 0.316, data_time: 0.007, memory: 18400, loss_cls: 0.3957, loss_bbox: 1.2790, loss_obj: 0.5777, loss: 2.2524
2022-07-13 19:12:26,017 - mmdet - INFO - Epoch [284][70/166]	lr: 5.007e-04, eta: 0:15:46, time: 0.235, data_time: 0.008, memory: 18400, loss_cls: 0.4084, loss_bbox: 1.3662, loss_obj: 0.6592, loss: 2.4338
2022-07-13 19:12:28,580 - mmdet - INFO - Epoch [284][80/166]	lr: 5.007e-04, eta: 0:15:39, time: 0.256, data_time: 0.008, memory: 18400, loss_cls: 0.4125, loss_bbox: 1.3863, loss_obj: 0.7044, loss: 2.5032
2022-07-13 19:12:31,918 - mmdet - INFO - Epoch [284][90/166]	lr: 5.006e-04, eta: 0:15:35, time: 0.334, data_time: 0.008, memory: 18400, loss_cls: 0.4020, loss_bbox: 1.3086, loss_obj: 0.6877, loss: 2.3983
2022-07-13 19:12:34,937 - mmdet - INFO - Epoch [284][100/166]	lr: 5.006e-04, eta: 0:15:29, time: 0.302, data_time: 0.008, memory: 18400, loss_cls: 0.3992, loss_bbox: 1.3097, loss_obj: 0.5838, loss: 2.2926
2022-07-13 19:12:38,501 - mmdet - INFO - Epoch [284][110/166]	lr: 5.005e-04, eta: 0:15:27, time: 0.356, data_time: 0.007, memory: 18400, loss_cls: 0.3901, loss_bbox: 1.2580, loss_obj: 0.6053, loss: 2.2535
2022-07-13 19:12:42,055 - mmdet - INFO - Epoch [284][120/166]	lr: 5.005e-04, eta: 0:15:24, time: 0.355, data_time: 0.007, memory: 18400, loss_cls: 0.4020, loss_bbox: 1.3281, loss_obj: 0.6479, loss: 2.3780
2022-07-13 19:12:45,740 - mmdet - INFO - Epoch [284][130/166]	lr: 5.004e-04, eta: 0:15:22, time: 0.368, data_time: 0.007, memory: 18400, loss_cls: 0.3956, loss_bbox: 1.2759, loss_obj: 0.6240, loss: 2.2955
2022-07-13 19:12:48,217 - mmdet - INFO - Epoch [284][140/166]	lr: 5.004e-04, eta: 0:15:14, time: 0.248, data_time: 0.008, memory: 18400, loss_cls: 0.4024, loss_bbox: 1.3467, loss_obj: 0.6496, loss: 2.3987
2022-07-13 19:12:51,461 - mmdet - INFO - Epoch [284][150/166]	lr: 5.004e-04, eta: 0:15:10, time: 0.324, data_time: 0.008, memory: 18400, loss_cls: 0.4093, loss_bbox: 1.3428, loss_obj: 0.6286, loss: 2.3807
2022-07-13 19:12:55,844 - mmdet - INFO - Epoch [284][160/166]	lr: 5.003e-04, eta: 0:15:11, time: 0.438, data_time: 0.007, memory: 18400, loss_cls: 0.4109, loss_bbox: 1.3588, loss_obj: 0.6396, loss: 2.4093
2022-07-13 19:12:57,593 - mmdet - INFO - No mosaic and mixup aug now!
2022-07-13 19:12:57,661 - mmdet - INFO - Add additional L1 loss now!
2022-07-13 19:13:03,100 - mmdet - INFO - Epoch [285][10/166]	lr: 5.003e-04, eta: 0:15:05, time: 0.543, data_time: 0.248, memory: 18400, loss_cls: 0.3713, loss_bbox: 1.1388, loss_obj: 0.6203, loss_l1: 0.3589, loss: 2.4894
2022-07-13 19:13:07,208 - mmdet - INFO - Epoch [285][20/166]	lr: 5.002e-04, eta: 0:15:04, time: 0.411, data_time: 0.007, memory: 18400, loss_cls: 0.3453, loss_bbox: 1.0279, loss_obj: 0.3888, loss_l1: 0.3689, loss: 2.1309
2022-07-13 19:13:10,873 - mmdet - INFO - Epoch [285][30/166]	lr: 5.002e-04, eta: 0:15:02, time: 0.367, data_time: 0.007, memory: 18400, loss_cls: 0.3538, loss_bbox: 1.0707, loss_obj: 0.3608, loss_l1: 0.3660, loss: 2.1512
2022-07-13 19:13:13,609 - mmdet - INFO - Epoch [285][40/166]	lr: 5.002e-04, eta: 0:14:56, time: 0.274, data_time: 0.007, memory: 18400, loss_cls: 0.3385, loss_bbox: 0.9982, loss_obj: 0.3093, loss_l1: 0.2958, loss: 1.9419
2022-07-13 19:13:16,864 - mmdet - INFO - Epoch [285][50/166]	lr: 5.001e-04, eta: 0:14:51, time: 0.325, data_time: 0.007, memory: 18400, loss_cls: 0.3502, loss_bbox: 1.0551, loss_obj: 0.2904, loss_l1: 0.3485, loss: 2.0441
2022-07-13 19:13:20,467 - mmdet - INFO - Epoch [285][60/166]	lr: 5.001e-04, eta: 0:14:49, time: 0.360, data_time: 0.007, memory: 18400, loss_cls: 0.3604, loss_bbox: 1.0970, loss_obj: 0.3079, loss_l1: 0.3569, loss: 2.1222
2022-07-13 19:13:24,111 - mmdet - INFO - Epoch [285][70/166]	lr: 5.001e-04, eta: 0:14:46, time: 0.364, data_time: 0.007, memory: 18400, loss_cls: 0.3406, loss_bbox: 1.0139, loss_obj: 0.3011, loss_l1: 0.3431, loss: 1.9987
2022-07-13 19:13:26,289 - mmdet - INFO - Epoch [285][80/166]	lr: 5.001e-04, eta: 0:14:38, time: 0.218, data_time: 0.007, memory: 18400, loss_cls: 0.3369, loss_bbox: 0.9950, loss_obj: 0.2440, loss_l1: 0.3129, loss: 1.8888
2022-07-13 19:13:28,912 - mmdet - INFO - Epoch [285][90/166]	lr: 5.001e-04, eta: 0:14:32, time: 0.262, data_time: 0.007, memory: 18400, loss_cls: 0.3373, loss_bbox: 0.9888, loss_obj: 0.2624, loss_l1: 0.3088, loss: 1.8972
2022-07-13 19:13:32,346 - mmdet - INFO - Epoch [285][100/166]	lr: 5.000e-04, eta: 0:14:29, time: 0.343, data_time: 0.007, memory: 18400, loss_cls: 0.3225, loss_bbox: 0.9295, loss_obj: 0.1839, loss_l1: 0.2967, loss: 1.7326
2022-07-13 19:13:36,109 - mmdet - INFO - Epoch [285][110/166]	lr: 5.000e-04, eta: 0:14:27, time: 0.376, data_time: 0.007, memory: 18400, loss_cls: 0.3316, loss_bbox: 0.9752, loss_obj: 0.2173, loss_l1: 0.3426, loss: 1.8667
2022-07-13 19:13:40,053 - mmdet - INFO - Epoch [285][120/166]	lr: 5.000e-04, eta: 0:14:25, time: 0.394, data_time: 0.007, memory: 18400, loss_cls: 0.3230, loss_bbox: 0.9329, loss_obj: 0.1958, loss_l1: 0.3412, loss: 1.7929
2022-07-13 19:13:42,720 - mmdet - INFO - Epoch [285][130/166]	lr: 5.000e-04, eta: 0:14:19, time: 0.267, data_time: 0.007, memory: 18400, loss_cls: 0.3444, loss_bbox: 1.0264, loss_obj: 0.2150, loss_l1: 0.3358, loss: 1.9216
2022-07-13 19:13:45,489 - mmdet - INFO - Epoch [285][140/166]	lr: 5.000e-04, eta: 0:14:14, time: 0.277, data_time: 0.007, memory: 18400, loss_cls: 0.3474, loss_bbox: 1.0442, loss_obj: 0.2654, loss_l1: 0.3433, loss: 2.0003
2022-07-13 19:13:49,084 - mmdet - INFO - Epoch [285][150/166]	lr: 5.000e-04, eta: 0:14:11, time: 0.359, data_time: 0.007, memory: 18400, loss_cls: 0.3298, loss_bbox: 0.9613, loss_obj: 0.2163, loss_l1: 0.3389, loss: 1.8463
2022-07-13 19:13:52,646 - mmdet - INFO - Epoch [285][160/166]	lr: 5.000e-04, eta: 0:14:08, time: 0.356, data_time: 0.007, memory: 18400, loss_cls: 0.3394, loss_bbox: 1.0081, loss_obj: 0.2457, loss_l1: 0.3529, loss: 1.9462
2022-07-13 19:13:57,669 - mmdet - INFO - Evaluating bbox...
2022-07-13 19:13:57,759 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.678
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.869
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.854
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.682
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.690
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.731
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.731
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.731
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.738
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.736

2022-07-13 19:13:57,760 - mmdet - INFO - Exp name: yolox_l_8x8_300e_coco_airbus.py
2022-07-13 19:13:57,760 - mmdet - INFO - Epoch(val) [285][142]	bbox_mAP: 0.6780, bbox_mAP_50: 0.8690, bbox_mAP_75: 0.8540, bbox_mAP_s: -1.0000, bbox_mAP_m: 0.6820, bbox_mAP_l: 0.6900, bbox_mAP_copypaste: 0.678 0.869 0.854 -1.000 0.682 0.690
2022-07-13 19:14:03,188 - mmdet - INFO - Epoch [286][10/166]	lr: 5.000e-04, eta: 0:14:03, time: 0.541, data_time: 0.222, memory: 18400, loss_cls: 0.3472, loss_bbox: 1.0434, loss_obj: 0.1934, loss_l1: 0.3370, loss: 1.9210
2022-07-13 19:14:06,728 - mmdet - INFO - Epoch [286][20/166]	lr: 5.000e-04, eta: 0:14:00, time: 0.354, data_time: 0.008, memory: 18400, loss_cls: 0.3341, loss_bbox: 0.9850, loss_obj: 0.2687, loss_l1: 0.3417, loss: 1.9295
2022-07-13 19:14:09,996 - mmdet - INFO - Epoch [286][30/166]	lr: 5.000e-04, eta: 0:13:56, time: 0.327, data_time: 0.007, memory: 18400, loss_cls: 0.3464, loss_bbox: 1.0378, loss_obj: 0.2963, loss_l1: 0.3577, loss: 2.0383
2022-07-13 19:14:12,760 - mmdet - INFO - Epoch [286][40/166]	lr: 5.000e-04, eta: 0:13:51, time: 0.276, data_time: 0.007, memory: 18400, loss_cls: 0.3626, loss_bbox: 1.1029, loss_obj: 0.2338, loss_l1: 0.3431, loss: 2.0425
2022-07-13 19:14:16,293 - mmdet - INFO - Epoch [286][50/166]	lr: 5.000e-04, eta: 0:13:48, time: 0.353, data_time: 0.007, memory: 18400, loss_cls: 0.3172, loss_bbox: 0.9103, loss_obj: 0.1583, loss_l1: 0.3020, loss: 1.6878
2022-07-13 19:14:20,404 - mmdet - INFO - Epoch [286][60/166]	lr: 5.000e-04, eta: 0:13:46, time: 0.411, data_time: 0.007, memory: 18400, loss_cls: 0.3332, loss_bbox: 0.9744, loss_obj: 0.2143, loss_l1: 0.3880, loss: 1.9099
2022-07-13 19:14:23,898 - mmdet - INFO - Epoch [286][70/166]	lr: 5.000e-04, eta: 0:13:43, time: 0.349, data_time: 0.007, memory: 18400, loss_cls: 0.3342, loss_bbox: 0.9869, loss_obj: 0.1915, loss_l1: 0.3487, loss: 1.8612
2022-07-13 19:14:26,763 - mmdet - INFO - Epoch [286][80/166]	lr: 5.000e-04, eta: 0:13:38, time: 0.286, data_time: 0.007, memory: 18400, loss_cls: 0.3542, loss_bbox: 1.0620, loss_obj: 0.2543, loss_l1: 0.3251, loss: 1.9957
2022-07-13 19:14:28,842 - mmdet - INFO - Epoch [286][90/166]	lr: 5.000e-04, eta: 0:13:31, time: 0.208, data_time: 0.007, memory: 18400, loss_cls: 0.3605, loss_bbox: 1.0957, loss_obj: 0.2377, loss_l1: 0.3455, loss: 2.0394
2022-07-13 19:14:33,200 - mmdet - INFO - Epoch [286][100/166]	lr: 5.000e-04, eta: 0:13:31, time: 0.436, data_time: 0.007, memory: 18400, loss_cls: 0.3307, loss_bbox: 0.9654, loss_obj: 0.2529, loss_l1: 0.3705, loss: 1.9196
2022-07-13 19:14:37,279 - mmdet - INFO - Epoch [286][110/166]	lr: 5.000e-04, eta: 0:13:29, time: 0.408, data_time: 0.007, memory: 18400, loss_cls: 0.3187, loss_bbox: 0.9220, loss_obj: 0.2384, loss_l1: 0.3263, loss: 1.8054
2022-07-13 19:14:40,263 - mmdet - INFO - Epoch [286][120/166]	lr: 5.000e-04, eta: 0:13:24, time: 0.298, data_time: 0.007, memory: 18400, loss_cls: 0.3240, loss_bbox: 0.9392, loss_obj: 0.1861, loss_l1: 0.2930, loss: 1.7422
2022-07-13 19:14:44,563 - mmdet - INFO - Epoch [286][130/166]	lr: 5.000e-04, eta: 0:13:23, time: 0.430, data_time: 0.007, memory: 18400, loss_cls: 0.3339, loss_bbox: 0.9745, loss_obj: 0.1984, loss_l1: 0.3513, loss: 1.8580
2022-07-13 19:14:48,925 - mmdet - INFO - Epoch [286][140/166]	lr: 5.000e-04, eta: 0:13:22, time: 0.436, data_time: 0.008, memory: 18400, loss_cls: 0.3394, loss_bbox: 1.0064, loss_obj: 0.2405, loss_l1: 0.3695, loss: 1.9557
2022-07-13 19:14:52,525 - mmdet - INFO - Epoch [286][150/166]	lr: 5.000e-04, eta: 0:13:19, time: 0.360, data_time: 0.007, memory: 18400, loss_cls: 0.3375, loss_bbox: 0.9939, loss_obj: 0.2777, loss_l1: 0.3171, loss: 1.9263
2022-07-13 19:14:56,828 - mmdet - INFO - Epoch [286][160/166]	lr: 5.000e-04, eta: 0:13:18, time: 0.430, data_time: 0.007, memory: 18400, loss_cls: 0.3296, loss_bbox: 0.9604, loss_obj: 0.2396, loss_l1: 0.3330, loss: 1.8626
2022-07-13 19:15:02,232 - mmdet - INFO - Evaluating bbox...
2022-07-13 19:15:02,320 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.679
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.870
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.855
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.682
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.691
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.731
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.731
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.731
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.738
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.736

2022-07-13 19:15:02,321 - mmdet - INFO - Exp name: yolox_l_8x8_300e_coco_airbus.py
2022-07-13 19:15:02,321 - mmdet - INFO - Epoch(val) [286][142]	bbox_mAP: 0.6790, bbox_mAP_50: 0.8700, bbox_mAP_75: 0.8550, bbox_mAP_s: -1.0000, bbox_mAP_m: 0.6820, bbox_mAP_l: 0.6910, bbox_mAP_copypaste: 0.679 0.870 0.855 -1.000 0.682 0.691
2022-07-13 19:15:08,456 - mmdet - INFO - Epoch [287][10/166]	lr: 5.000e-04, eta: 0:13:14, time: 0.612, data_time: 0.222, memory: 18400, loss_cls: 0.3298, loss_bbox: 0.9684, loss_obj: 0.2048, loss_l1: 0.3326, loss: 1.8356
2022-07-13 19:15:11,762 - mmdet - INFO - Epoch [287][20/166]	lr: 5.000e-04, eta: 0:13:10, time: 0.331, data_time: 0.008, memory: 18400, loss_cls: 0.3347, loss_bbox: 0.9890, loss_obj: 0.2014, loss_l1: 0.3216, loss: 1.8468
2022-07-13 19:15:15,157 - mmdet - INFO - Epoch [287][30/166]	lr: 5.000e-04, eta: 0:13:07, time: 0.340, data_time: 0.008, memory: 18400, loss_cls: 0.3331, loss_bbox: 0.9756, loss_obj: 0.1975, loss_l1: 0.3237, loss: 1.8299
2022-07-13 19:15:18,393 - mmdet - INFO - Epoch [287][40/166]	lr: 5.000e-04, eta: 0:13:03, time: 0.324, data_time: 0.009, memory: 18400, loss_cls: 0.3497, loss_bbox: 1.0484, loss_obj: 0.2036, loss_l1: 0.3581, loss: 1.9599
2022-07-13 19:15:21,984 - mmdet - INFO - Epoch [287][50/166]	lr: 5.000e-04, eta: 0:13:00, time: 0.359, data_time: 0.007, memory: 18400, loss_cls: 0.3310, loss_bbox: 0.9693, loss_obj: 0.1752, loss_l1: 0.3168, loss: 1.7923
2022-07-13 19:15:25,317 - mmdet - INFO - Epoch [287][60/166]	lr: 5.000e-04, eta: 0:12:56, time: 0.333, data_time: 0.007, memory: 18400, loss_cls: 0.3393, loss_bbox: 1.0005, loss_obj: 0.2376, loss_l1: 0.3616, loss: 1.9390
2022-07-13 19:15:27,754 - mmdet - INFO - Epoch [287][70/166]	lr: 5.000e-04, eta: 0:12:50, time: 0.244, data_time: 0.007, memory: 18400, loss_cls: 0.3269, loss_bbox: 0.9493, loss_obj: 0.2194, loss_l1: 0.2927, loss: 1.7883
2022-07-13 19:15:31,284 - mmdet - INFO - Epoch [287][80/166]	lr: 5.000e-04, eta: 0:12:47, time: 0.353, data_time: 0.007, memory: 18400, loss_cls: 0.3422, loss_bbox: 1.0118, loss_obj: 0.2627, loss_l1: 0.3369, loss: 1.9536
2022-07-13 19:15:35,799 - mmdet - INFO - Epoch [287][90/166]	lr: 5.000e-04, eta: 0:12:46, time: 0.451, data_time: 0.007, memory: 18400, loss_cls: 0.3372, loss_bbox: 0.9933, loss_obj: 0.1972, loss_l1: 0.3713, loss: 1.8990
2022-07-13 19:15:40,423 - mmdet - INFO - Epoch [287][100/166]	lr: 5.000e-04, eta: 0:12:45, time: 0.462, data_time: 0.007, memory: 18400, loss_cls: 0.3564, loss_bbox: 1.0828, loss_obj: 0.3171, loss_l1: 0.4156, loss: 2.1719
2022-07-13 19:15:43,985 - mmdet - INFO - Epoch [287][110/166]	lr: 5.000e-04, eta: 0:12:42, time: 0.356, data_time: 0.007, memory: 18400, loss_cls: 0.3463, loss_bbox: 1.0291, loss_obj: 0.2379, loss_l1: 0.3511, loss: 1.9644
2022-07-13 19:15:47,537 - mmdet - INFO - Epoch [287][120/166]	lr: 5.000e-04, eta: 0:12:39, time: 0.355, data_time: 0.007, memory: 18400, loss_cls: 0.3359, loss_bbox: 0.9902, loss_obj: 0.1999, loss_l1: 0.3233, loss: 1.8493
2022-07-13 19:15:50,565 - mmdet - INFO - Epoch [287][130/166]	lr: 5.000e-04, eta: 0:12:34, time: 0.303, data_time: 0.007, memory: 18400, loss_cls: 0.3339, loss_bbox: 0.9837, loss_obj: 0.2386, loss_l1: 0.3185, loss: 1.8747
2022-07-13 19:15:53,963 - mmdet - INFO - Epoch [287][140/166]	lr: 5.000e-04, eta: 0:12:31, time: 0.340, data_time: 0.008, memory: 18400, loss_cls: 0.3453, loss_bbox: 1.0266, loss_obj: 0.2260, loss_l1: 0.3322, loss: 1.9300
2022-07-13 19:15:56,852 - mmdet - INFO - Epoch [287][150/166]	lr: 5.000e-04, eta: 0:12:26, time: 0.289, data_time: 0.007, memory: 18400, loss_cls: 0.3219, loss_bbox: 0.9250, loss_obj: 0.2015, loss_l1: 0.2971, loss: 1.7456
2022-07-13 19:15:59,620 - mmdet - INFO - Epoch [287][160/166]	lr: 5.000e-04, eta: 0:12:22, time: 0.277, data_time: 0.007, memory: 18400, loss_cls: 0.3315, loss_bbox: 0.9782, loss_obj: 0.1770, loss_l1: 0.3137, loss: 1.8004
2022-07-13 19:16:04,550 - mmdet - INFO - Evaluating bbox...
2022-07-13 19:16:04,635 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.679
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.871
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.856
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.682
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.691
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.730
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.730
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.730
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.738
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.736

2022-07-13 19:16:04,636 - mmdet - INFO - Exp name: yolox_l_8x8_300e_coco_airbus.py
2022-07-13 19:16:04,636 - mmdet - INFO - Epoch(val) [287][142]	bbox_mAP: 0.6790, bbox_mAP_50: 0.8710, bbox_mAP_75: 0.8560, bbox_mAP_s: -1.0000, bbox_mAP_m: 0.6820, bbox_mAP_l: 0.6910, bbox_mAP_copypaste: 0.679 0.871 0.856 -1.000 0.682 0.691
2022-07-13 19:16:10,007 - mmdet - INFO - Epoch [288][10/166]	lr: 5.000e-04, eta: 0:12:16, time: 0.535, data_time: 0.221, memory: 18400, loss_cls: 0.3335, loss_bbox: 0.9811, loss_obj: 0.1758, loss_l1: 0.3367, loss: 1.8270
2022-07-13 19:16:12,118 - mmdet - INFO - Epoch [288][20/166]	lr: 5.000e-04, eta: 0:12:10, time: 0.211, data_time: 0.007, memory: 18400, loss_cls: 0.3513, loss_bbox: 1.0579, loss_obj: 0.2343, loss_l1: 0.3272, loss: 1.9707
2022-07-13 19:16:14,603 - mmdet - INFO - Epoch [288][30/166]	lr: 5.000e-04, eta: 0:12:05, time: 0.249, data_time: 0.007, memory: 18400, loss_cls: 0.3216, loss_bbox: 0.9346, loss_obj: 0.1937, loss_l1: 0.2950, loss: 1.7449
2022-07-13 19:16:17,754 - mmdet - INFO - Epoch [288][40/166]	lr: 5.000e-04, eta: 0:12:01, time: 0.315, data_time: 0.007, memory: 18400, loss_cls: 0.3357, loss_bbox: 0.9976, loss_obj: 0.1851, loss_l1: 0.3192, loss: 1.8377
2022-07-13 19:16:20,770 - mmdet - INFO - Epoch [288][50/166]	lr: 5.000e-04, eta: 0:11:57, time: 0.302, data_time: 0.007, memory: 18400, loss_cls: 0.3326, loss_bbox: 0.9756, loss_obj: 0.1981, loss_l1: 0.3194, loss: 1.8257
2022-07-13 19:16:23,540 - mmdet - INFO - Epoch [288][60/166]	lr: 5.000e-04, eta: 0:11:53, time: 0.277, data_time: 0.007, memory: 18400, loss_cls: 0.3463, loss_bbox: 1.0369, loss_obj: 0.2238, loss_l1: 0.3369, loss: 1.9439
2022-07-13 19:16:26,066 - mmdet - INFO - Epoch [288][70/166]	lr: 5.000e-04, eta: 0:11:48, time: 0.253, data_time: 0.007, memory: 18400, loss_cls: 0.3436, loss_bbox: 1.0190, loss_obj: 0.2371, loss_l1: 0.3055, loss: 1.9051
2022-07-13 19:16:29,668 - mmdet - INFO - Epoch [288][80/166]	lr: 5.000e-04, eta: 0:11:45, time: 0.360, data_time: 0.007, memory: 18400, loss_cls: 0.3331, loss_bbox: 0.9792, loss_obj: 0.1984, loss_l1: 0.3278, loss: 1.8385
2022-07-13 19:16:33,710 - mmdet - INFO - Epoch [288][90/166]	lr: 5.000e-04, eta: 0:11:42, time: 0.404, data_time: 0.008, memory: 18400, loss_cls: 0.3301, loss_bbox: 0.9715, loss_obj: 0.2023, loss_l1: 0.3622, loss: 1.8661
2022-07-13 19:16:38,257 - mmdet - INFO - Epoch [288][100/166]	lr: 5.000e-04, eta: 0:11:41, time: 0.455, data_time: 0.007, memory: 18400, loss_cls: 0.3460, loss_bbox: 1.0290, loss_obj: 0.2178, loss_l1: 0.3782, loss: 1.9710
2022-07-13 19:16:41,614 - mmdet - INFO - Epoch [288][110/166]	lr: 5.000e-04, eta: 0:11:37, time: 0.336, data_time: 0.008, memory: 18400, loss_cls: 0.3206, loss_bbox: 0.9297, loss_obj: 0.1630, loss_l1: 0.2924, loss: 1.7057
2022-07-13 19:16:44,912 - mmdet - INFO - Epoch [288][120/166]	lr: 5.000e-04, eta: 0:11:34, time: 0.330, data_time: 0.007, memory: 18400, loss_cls: 0.3299, loss_bbox: 0.9693, loss_obj: 0.1812, loss_l1: 0.3099, loss: 1.7903
2022-07-13 19:16:47,437 - mmdet - INFO - Epoch [288][130/166]	lr: 5.000e-04, eta: 0:11:29, time: 0.252, data_time: 0.007, memory: 18400, loss_cls: 0.3354, loss_bbox: 0.9869, loss_obj: 0.2140, loss_l1: 0.2877, loss: 1.8240
2022-07-13 19:16:50,954 - mmdet - INFO - Epoch [288][140/166]	lr: 5.000e-04, eta: 0:11:26, time: 0.352, data_time: 0.007, memory: 18400, loss_cls: 0.3222, loss_bbox: 0.9360, loss_obj: 0.2265, loss_l1: 0.3141, loss: 1.7987
2022-07-13 19:16:54,996 - mmdet - INFO - Epoch [288][150/166]	lr: 5.000e-04, eta: 0:11:23, time: 0.404, data_time: 0.007, memory: 18400, loss_cls: 0.3154, loss_bbox: 0.9042, loss_obj: 0.1944, loss_l1: 0.3201, loss: 1.7342
2022-07-13 19:16:57,994 - mmdet - INFO - Epoch [288][160/166]	lr: 5.000e-04, eta: 0:11:19, time: 0.300, data_time: 0.008, memory: 18400, loss_cls: 0.3437, loss_bbox: 1.0204, loss_obj: 0.2466, loss_l1: 0.3214, loss: 1.9320
2022-07-13 19:17:02,911 - mmdet - INFO - Evaluating bbox...
2022-07-13 19:17:02,993 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.678
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.872
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.857
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.681
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.690
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.730
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.730
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.730
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.738
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.735

2022-07-13 19:17:02,994 - mmdet - INFO - Exp name: yolox_l_8x8_300e_coco_airbus.py
2022-07-13 19:17:02,994 - mmdet - INFO - Epoch(val) [288][142]	bbox_mAP: 0.6780, bbox_mAP_50: 0.8720, bbox_mAP_75: 0.8570, bbox_mAP_s: -1.0000, bbox_mAP_m: 0.6810, bbox_mAP_l: 0.6900, bbox_mAP_copypaste: 0.678 0.872 0.857 -1.000 0.681 0.690
2022-07-13 19:17:08,538 - mmdet - INFO - Epoch [289][10/166]	lr: 5.000e-04, eta: 0:11:14, time: 0.553, data_time: 0.222, memory: 18400, loss_cls: 0.3389, loss_bbox: 1.0021, loss_obj: 0.1973, loss_l1: 0.3359, loss: 1.8741
2022-07-13 19:17:11,702 - mmdet - INFO - Epoch [289][20/166]	lr: 5.000e-04, eta: 0:11:10, time: 0.316, data_time: 0.007, memory: 18400, loss_cls: 0.3303, loss_bbox: 0.9708, loss_obj: 0.2102, loss_l1: 0.3143, loss: 1.8255
2022-07-13 19:17:15,301 - mmdet - INFO - Epoch [289][30/166]	lr: 5.000e-04, eta: 0:11:07, time: 0.360, data_time: 0.007, memory: 18400, loss_cls: 0.3206, loss_bbox: 0.9290, loss_obj: 0.1772, loss_l1: 0.3283, loss: 1.7551
2022-07-13 19:17:17,715 - mmdet - INFO - Epoch [289][40/166]	lr: 5.000e-04, eta: 0:11:02, time: 0.241, data_time: 0.007, memory: 18400, loss_cls: 0.3365, loss_bbox: 0.9913, loss_obj: 0.2006, loss_l1: 0.2983, loss: 1.8267
2022-07-13 19:17:21,122 - mmdet - INFO - Epoch [289][50/166]	lr: 5.000e-04, eta: 0:10:59, time: 0.341, data_time: 0.007, memory: 18400, loss_cls: 0.3414, loss_bbox: 1.0155, loss_obj: 0.1941, loss_l1: 0.3509, loss: 1.9019
2022-07-13 19:17:24,643 - mmdet - INFO - Epoch [289][60/166]	lr: 5.000e-04, eta: 0:10:56, time: 0.352, data_time: 0.007, memory: 18400, loss_cls: 0.3180, loss_bbox: 0.9157, loss_obj: 0.1914, loss_l1: 0.3081, loss: 1.7332
2022-07-13 19:17:27,000 - mmdet - INFO - Epoch [289][70/166]	lr: 5.000e-04, eta: 0:10:51, time: 0.236, data_time: 0.007, memory: 18400, loss_cls: 0.3414, loss_bbox: 1.0155, loss_obj: 0.2421, loss_l1: 0.3074, loss: 1.9065
2022-07-13 19:17:30,826 - mmdet - INFO - Epoch [289][80/166]	lr: 5.000e-04, eta: 0:10:48, time: 0.382, data_time: 0.007, memory: 18400, loss_cls: 0.3315, loss_bbox: 0.9607, loss_obj: 0.1886, loss_l1: 0.3333, loss: 1.8141
2022-07-13 19:17:35,092 - mmdet - INFO - Epoch [289][90/166]	lr: 5.000e-04, eta: 0:10:46, time: 0.427, data_time: 0.007, memory: 18400, loss_cls: 0.3278, loss_bbox: 0.9559, loss_obj: 0.2188, loss_l1: 0.3433, loss: 1.8458
2022-07-13 19:17:38,240 - mmdet - INFO - Epoch [289][100/166]	lr: 5.000e-04, eta: 0:10:42, time: 0.315, data_time: 0.007, memory: 18400, loss_cls: 0.3235, loss_bbox: 0.9375, loss_obj: 0.1731, loss_l1: 0.2896, loss: 1.7237
2022-07-13 19:17:40,617 - mmdet - INFO - Epoch [289][110/166]	lr: 5.000e-04, eta: 0:10:37, time: 0.238, data_time: 0.007, memory: 18400, loss_cls: 0.3525, loss_bbox: 1.0569, loss_obj: 0.2161, loss_l1: 0.3071, loss: 1.9326
2022-07-13 19:17:43,639 - mmdet - INFO - Epoch [289][120/166]	lr: 5.000e-04, eta: 0:10:34, time: 0.302, data_time: 0.007, memory: 18400, loss_cls: 0.3222, loss_bbox: 0.9357, loss_obj: 0.1945, loss_l1: 0.3081, loss: 1.7605
2022-07-13 19:17:47,246 - mmdet - INFO - Epoch [289][130/166]	lr: 5.000e-04, eta: 0:10:30, time: 0.361, data_time: 0.007, memory: 18400, loss_cls: 0.3344, loss_bbox: 0.9884, loss_obj: 0.2582, loss_l1: 0.3255, loss: 1.9065
2022-07-13 19:17:49,668 - mmdet - INFO - Epoch [289][140/166]	lr: 5.000e-04, eta: 0:10:26, time: 0.242, data_time: 0.008, memory: 18400, loss_cls: 0.3358, loss_bbox: 0.9953, loss_obj: 0.1598, loss_l1: 0.2943, loss: 1.7854
2022-07-13 19:17:53,504 - mmdet - INFO - Epoch [289][150/166]	lr: 5.000e-04, eta: 0:10:23, time: 0.384, data_time: 0.007, memory: 18400, loss_cls: 0.3500, loss_bbox: 1.0501, loss_obj: 0.2528, loss_l1: 0.3427, loss: 1.9956
2022-07-13 19:17:56,444 - mmdet - INFO - Epoch [289][160/166]	lr: 5.000e-04, eta: 0:10:19, time: 0.294, data_time: 0.007, memory: 18400, loss_cls: 0.3320, loss_bbox: 0.9797, loss_obj: 0.1588, loss_l1: 0.3024, loss: 1.7728
2022-07-13 19:18:01,098 - mmdet - INFO - Evaluating bbox...
2022-07-13 19:18:01,179 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.679
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.872
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.857
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.680
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.691
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.729
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.729
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.729
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.737
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.735

2022-07-13 19:18:01,180 - mmdet - INFO - Exp name: yolox_l_8x8_300e_coco_airbus.py
2022-07-13 19:18:01,180 - mmdet - INFO - Epoch(val) [289][142]	bbox_mAP: 0.6790, bbox_mAP_50: 0.8720, bbox_mAP_75: 0.8570, bbox_mAP_s: -1.0000, bbox_mAP_m: 0.6800, bbox_mAP_l: 0.6910, bbox_mAP_copypaste: 0.679 0.872 0.857 -1.000 0.680 0.691
2022-07-13 19:18:06,413 - mmdet - INFO - Epoch [290][10/166]	lr: 5.000e-04, eta: 0:10:13, time: 0.521, data_time: 0.223, memory: 18400, loss_cls: 0.3193, loss_bbox: 0.9289, loss_obj: 0.1688, loss_l1: 0.3029, loss: 1.7199
2022-07-13 19:18:09,950 - mmdet - INFO - Epoch [290][20/166]	lr: 5.000e-04, eta: 0:10:10, time: 0.354, data_time: 0.008, memory: 18400, loss_cls: 0.3430, loss_bbox: 1.0127, loss_obj: 0.2677, loss_l1: 0.3316, loss: 1.9549
2022-07-13 19:18:13,654 - mmdet - INFO - Epoch [290][30/166]	lr: 5.000e-04, eta: 0:10:07, time: 0.370, data_time: 0.007, memory: 18400, loss_cls: 0.3115, loss_bbox: 0.8927, loss_obj: 0.1717, loss_l1: 0.2965, loss: 1.6724
2022-07-13 19:18:18,019 - mmdet - INFO - Epoch [290][40/166]	lr: 5.000e-04, eta: 0:10:05, time: 0.437, data_time: 0.008, memory: 18400, loss_cls: 0.3294, loss_bbox: 0.9641, loss_obj: 0.1876, loss_l1: 0.3582, loss: 1.8393
2022-07-13 19:18:21,509 - mmdet - INFO - Epoch [290][50/166]	lr: 5.000e-04, eta: 0:10:02, time: 0.349, data_time: 0.007, memory: 18400, loss_cls: 0.3337, loss_bbox: 0.9842, loss_obj: 0.1576, loss_l1: 0.3215, loss: 1.7971
2022-07-13 19:18:25,086 - mmdet - INFO - Epoch [290][60/166]	lr: 5.000e-04, eta: 0:09:59, time: 0.358, data_time: 0.007, memory: 18400, loss_cls: 0.3215, loss_bbox: 0.9317, loss_obj: 0.1509, loss_l1: 0.3113, loss: 1.7154
2022-07-13 19:18:28,470 - mmdet - INFO - Epoch [290][70/166]	lr: 5.000e-04, eta: 0:09:55, time: 0.338, data_time: 0.007, memory: 18400, loss_cls: 0.3216, loss_bbox: 0.9296, loss_obj: 0.1462, loss_l1: 0.3062, loss: 1.7037
2022-07-13 19:18:31,750 - mmdet - INFO - Epoch [290][80/166]	lr: 5.000e-04, eta: 0:09:52, time: 0.328, data_time: 0.007, memory: 18400, loss_cls: 0.3135, loss_bbox: 0.8987, loss_obj: 0.1872, loss_l1: 0.2916, loss: 1.6911
2022-07-13 19:18:34,964 - mmdet - INFO - Epoch [290][90/166]	lr: 5.000e-04, eta: 0:09:48, time: 0.321, data_time: 0.008, memory: 18400, loss_cls: 0.3209, loss_bbox: 0.9309, loss_obj: 0.1811, loss_l1: 0.3115, loss: 1.7443
2022-07-13 19:18:37,446 - mmdet - INFO - Epoch [290][100/166]	lr: 5.000e-04, eta: 0:09:44, time: 0.248, data_time: 0.007, memory: 18400, loss_cls: 0.3033, loss_bbox: 0.8550, loss_obj: 0.1933, loss_l1: 0.2382, loss: 1.5898
2022-07-13 19:18:39,948 - mmdet - INFO - Epoch [290][110/166]	lr: 5.000e-04, eta: 0:09:39, time: 0.250, data_time: 0.007, memory: 18400, loss_cls: 0.3229, loss_bbox: 0.9458, loss_obj: 0.1959, loss_l1: 0.2854, loss: 1.7500
2022-07-13 19:18:42,372 - mmdet - INFO - Epoch [290][120/166]	lr: 5.000e-04, eta: 0:09:35, time: 0.242, data_time: 0.007, memory: 18400, loss_cls: 0.3515, loss_bbox: 1.0488, loss_obj: 0.2554, loss_l1: 0.3095, loss: 1.9651
2022-07-13 19:18:45,710 - mmdet - INFO - Epoch [290][130/166]	lr: 5.000e-04, eta: 0:09:32, time: 0.334, data_time: 0.007, memory: 18400, loss_cls: 0.3139, loss_bbox: 0.8985, loss_obj: 0.1519, loss_l1: 0.2934, loss: 1.6577
2022-07-13 19:18:50,095 - mmdet - INFO - Epoch [290][140/166]	lr: 5.000e-04, eta: 0:09:29, time: 0.438, data_time: 0.007, memory: 18400, loss_cls: 0.3323, loss_bbox: 0.9792, loss_obj: 0.2423, loss_l1: 0.3328, loss: 1.8865
2022-07-13 19:18:53,647 - mmdet - INFO - Epoch [290][150/166]	lr: 5.000e-04, eta: 0:09:26, time: 0.355, data_time: 0.008, memory: 18400, loss_cls: 0.3381, loss_bbox: 0.9963, loss_obj: 0.1974, loss_l1: 0.3229, loss: 1.8548
2022-07-13 19:18:56,155 - mmdet - INFO - Epoch [290][160/166]	lr: 5.000e-04, eta: 0:09:22, time: 0.251, data_time: 0.007, memory: 18400, loss_cls: 0.3528, loss_bbox: 1.0658, loss_obj: 0.1992, loss_l1: 0.3269, loss: 1.9448
2022-07-13 19:18:57,770 - mmdet - INFO - Saving checkpoint at 290 epochs
2022-07-13 19:19:01,918 - mmdet - INFO - Evaluating bbox...
2022-07-13 19:19:01,997 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.680
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.873
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.858
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.680
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.692
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.730
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.730
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.730
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.737
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.736

2022-07-13 19:19:01,998 - mmdet - INFO - Exp name: yolox_l_8x8_300e_coco_airbus.py
2022-07-13 19:19:01,998 - mmdet - INFO - Epoch(val) [290][142]	bbox_mAP: 0.6800, bbox_mAP_50: 0.8730, bbox_mAP_75: 0.8580, bbox_mAP_s: -1.0000, bbox_mAP_m: 0.6800, bbox_mAP_l: 0.6920, bbox_mAP_copypaste: 0.680 0.873 0.858 -1.000 0.680 0.692
2022-07-13 19:19:07,381 - mmdet - INFO - Epoch [291][10/166]	lr: 5.000e-04, eta: 0:09:16, time: 0.536, data_time: 0.223, memory: 18400, loss_cls: 0.3234, loss_bbox: 0.9358, loss_obj: 0.2144, loss_l1: 0.3136, loss: 1.7871
2022-07-13 19:19:10,053 - mmdet - INFO - Epoch [291][20/166]	lr: 5.000e-04, eta: 0:09:12, time: 0.267, data_time: 0.007, memory: 18400, loss_cls: 0.3265, loss_bbox: 0.9460, loss_obj: 0.1570, loss_l1: 0.2709, loss: 1.7003
2022-07-13 19:19:14,882 - mmdet - INFO - Epoch [291][30/166]	lr: 5.000e-04, eta: 0:09:10, time: 0.483, data_time: 0.008, memory: 18400, loss_cls: 0.3302, loss_bbox: 0.9676, loss_obj: 0.1724, loss_l1: 0.3656, loss: 1.8358
2022-07-13 19:19:19,827 - mmdet - INFO - Epoch [291][40/166]	lr: 5.000e-04, eta: 0:09:08, time: 0.495, data_time: 0.008, memory: 18400, loss_cls: 0.3279, loss_bbox: 0.9548, loss_obj: 0.2321, loss_l1: 0.3513, loss: 1.8661
2022-07-13 19:19:22,496 - mmdet - INFO - Epoch [291][50/166]	lr: 5.000e-04, eta: 0:09:04, time: 0.267, data_time: 0.007, memory: 18400, loss_cls: 0.3143, loss_bbox: 0.9021, loss_obj: 0.1819, loss_l1: 0.2710, loss: 1.6693
2022-07-13 19:19:25,257 - mmdet - INFO - Epoch [291][60/166]	lr: 5.000e-04, eta: 0:09:00, time: 0.276, data_time: 0.008, memory: 18400, loss_cls: 0.3048, loss_bbox: 0.8634, loss_obj: 0.1762, loss_l1: 0.2556, loss: 1.6000
2022-07-13 19:19:28,014 - mmdet - INFO - Epoch [291][70/166]	lr: 5.000e-04, eta: 0:08:56, time: 0.276, data_time: 0.008, memory: 18400, loss_cls: 0.3231, loss_bbox: 0.9381, loss_obj: 0.1752, loss_l1: 0.2626, loss: 1.6991
2022-07-13 19:19:30,991 - mmdet - INFO - Epoch [291][80/166]	lr: 5.000e-04, eta: 0:08:53, time: 0.298, data_time: 0.007, memory: 18400, loss_cls: 0.3215, loss_bbox: 0.9262, loss_obj: 0.1566, loss_l1: 0.2801, loss: 1.6844
2022-07-13 19:19:33,784 - mmdet - INFO - Epoch [291][90/166]	lr: 5.000e-04, eta: 0:08:49, time: 0.279, data_time: 0.008, memory: 18400, loss_cls: 0.3307, loss_bbox: 0.9755, loss_obj: 0.1880, loss_l1: 0.2894, loss: 1.7836
2022-07-13 19:19:38,114 - mmdet - INFO - Epoch [291][100/166]	lr: 5.000e-04, eta: 0:08:46, time: 0.433, data_time: 0.008, memory: 18400, loss_cls: 0.3149, loss_bbox: 0.9063, loss_obj: 0.1636, loss_l1: 0.3410, loss: 1.7258
2022-07-13 19:19:42,228 - mmdet - INFO - Epoch [291][110/166]	lr: 5.000e-04, eta: 0:08:44, time: 0.411, data_time: 0.007, memory: 18400, loss_cls: 0.3365, loss_bbox: 0.9984, loss_obj: 0.1829, loss_l1: 0.3608, loss: 1.8786
2022-07-13 19:19:46,632 - mmdet - INFO - Epoch [291][120/166]	lr: 5.000e-04, eta: 0:08:41, time: 0.440, data_time: 0.008, memory: 18400, loss_cls: 0.3305, loss_bbox: 0.9656, loss_obj: 0.2000, loss_l1: 0.3355, loss: 1.8316
2022-07-13 19:19:49,126 - mmdet - INFO - Epoch [291][130/166]	lr: 5.000e-04, eta: 0:08:37, time: 0.249, data_time: 0.009, memory: 18400, loss_cls: 0.3501, loss_bbox: 1.0505, loss_obj: 0.2193, loss_l1: 0.3077, loss: 1.9276
2022-07-13 19:19:53,831 - mmdet - INFO - Epoch [291][140/166]	lr: 5.000e-04, eta: 0:08:35, time: 0.470, data_time: 0.008, memory: 18400, loss_cls: 0.3224, loss_bbox: 0.9298, loss_obj: 0.1814, loss_l1: 0.3579, loss: 1.7915
2022-07-13 19:19:57,378 - mmdet - INFO - Epoch [291][150/166]	lr: 5.000e-04, eta: 0:08:31, time: 0.355, data_time: 0.007, memory: 18400, loss_cls: 0.3266, loss_bbox: 0.9528, loss_obj: 0.2081, loss_l1: 0.3188, loss: 1.8062
2022-07-13 19:20:00,931 - mmdet - INFO - Epoch [291][160/166]	lr: 5.000e-04, eta: 0:08:28, time: 0.355, data_time: 0.007, memory: 18400, loss_cls: 0.3299, loss_bbox: 0.9675, loss_obj: 0.1503, loss_l1: 0.3113, loss: 1.7591
2022-07-13 19:20:06,308 - mmdet - INFO - Evaluating bbox...
2022-07-13 19:20:06,396 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.682
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.874
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.859
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.681
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.695
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.731
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.731
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.731
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.738
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.737

2022-07-13 19:20:06,397 - mmdet - INFO - Exp name: yolox_l_8x8_300e_coco_airbus.py
2022-07-13 19:20:06,398 - mmdet - INFO - Epoch(val) [291][142]	bbox_mAP: 0.6820, bbox_mAP_50: 0.8740, bbox_mAP_75: 0.8590, bbox_mAP_s: -1.0000, bbox_mAP_m: 0.6810, bbox_mAP_l: 0.6950, bbox_mAP_copypaste: 0.682 0.874 0.859 -1.000 0.681 0.695
2022-07-13 19:20:12,985 - mmdet - INFO - Epoch [292][10/166]	lr: 5.000e-04, eta: 0:08:24, time: 0.657, data_time: 0.224, memory: 18400, loss_cls: 0.3256, loss_bbox: 0.9477, loss_obj: 0.2064, loss_l1: 0.3615, loss: 1.8412
2022-07-13 19:20:16,183 - mmdet - INFO - Epoch [292][20/166]	lr: 5.000e-04, eta: 0:08:20, time: 0.320, data_time: 0.008, memory: 18400, loss_cls: 0.3271, loss_bbox: 0.9482, loss_obj: 0.2581, loss_l1: 0.3181, loss: 1.8516
2022-07-13 19:20:18,923 - mmdet - INFO - Epoch [292][30/166]	lr: 5.000e-04, eta: 0:08:16, time: 0.274, data_time: 0.008, memory: 18400, loss_cls: 0.3292, loss_bbox: 0.9688, loss_obj: 0.1748, loss_l1: 0.2946, loss: 1.7673
2022-07-13 19:20:23,071 - mmdet - INFO - Epoch [292][40/166]	lr: 5.000e-04, eta: 0:08:13, time: 0.415, data_time: 0.008, memory: 18400, loss_cls: 0.3073, loss_bbox: 0.8694, loss_obj: 0.2323, loss_l1: 0.3045, loss: 1.7134
2022-07-13 19:20:27,357 - mmdet - INFO - Epoch [292][50/166]	lr: 5.000e-04, eta: 0:08:11, time: 0.429, data_time: 0.008, memory: 18400, loss_cls: 0.3393, loss_bbox: 1.0020, loss_obj: 0.2103, loss_l1: 0.3509, loss: 1.9025
2022-07-13 19:20:30,953 - mmdet - INFO - Epoch [292][60/166]	lr: 5.000e-04, eta: 0:08:07, time: 0.360, data_time: 0.008, memory: 18400, loss_cls: 0.3281, loss_bbox: 0.9590, loss_obj: 0.1708, loss_l1: 0.3129, loss: 1.7709
2022-07-13 19:20:34,789 - mmdet - INFO - Epoch [292][70/166]	lr: 5.000e-04, eta: 0:08:04, time: 0.384, data_time: 0.008, memory: 18400, loss_cls: 0.3113, loss_bbox: 0.8945, loss_obj: 0.1710, loss_l1: 0.3077, loss: 1.6845
2022-07-13 19:20:38,308 - mmdet - INFO - Epoch [292][80/166]	lr: 5.000e-04, eta: 0:08:01, time: 0.352, data_time: 0.008, memory: 18400, loss_cls: 0.3120, loss_bbox: 0.8968, loss_obj: 0.1398, loss_l1: 0.3019, loss: 1.6506
2022-07-13 19:20:41,275 - mmdet - INFO - Epoch [292][90/166]	lr: 5.000e-04, eta: 0:07:57, time: 0.297, data_time: 0.008, memory: 18400, loss_cls: 0.3226, loss_bbox: 0.9373, loss_obj: 0.1656, loss_l1: 0.2898, loss: 1.7153
2022-07-13 19:20:44,199 - mmdet - INFO - Epoch [292][100/166]	lr: 5.000e-04, eta: 0:07:54, time: 0.292, data_time: 0.008, memory: 18400, loss_cls: 0.3246, loss_bbox: 0.9408, loss_obj: 0.1744, loss_l1: 0.2842, loss: 1.7240
2022-07-13 19:20:46,984 - mmdet - INFO - Epoch [292][110/166]	lr: 5.000e-04, eta: 0:07:50, time: 0.279, data_time: 0.008, memory: 18400, loss_cls: 0.3227, loss_bbox: 0.9382, loss_obj: 0.1893, loss_l1: 0.2753, loss: 1.7255
2022-07-13 19:20:50,942 - mmdet - INFO - Epoch [292][120/166]	lr: 5.000e-04, eta: 0:07:47, time: 0.396, data_time: 0.008, memory: 18400, loss_cls: 0.3404, loss_bbox: 1.0098, loss_obj: 0.1967, loss_l1: 0.3422, loss: 1.8892
2022-07-13 19:20:55,083 - mmdet - INFO - Epoch [292][130/166]	lr: 5.000e-04, eta: 0:07:44, time: 0.414, data_time: 0.007, memory: 18400, loss_cls: 0.3465, loss_bbox: 1.0301, loss_obj: 0.2027, loss_l1: 0.3692, loss: 1.9485
2022-07-13 19:20:58,582 - mmdet - INFO - Epoch [292][140/166]	lr: 5.000e-04, eta: 0:07:40, time: 0.350, data_time: 0.008, memory: 18400, loss_cls: 0.3209, loss_bbox: 0.9238, loss_obj: 0.1668, loss_l1: 0.3003, loss: 1.7118
2022-07-13 19:21:01,603 - mmdet - INFO - Epoch [292][150/166]	lr: 5.000e-04, eta: 0:07:37, time: 0.302, data_time: 0.008, memory: 18400, loss_cls: 0.3345, loss_bbox: 0.9831, loss_obj: 0.1922, loss_l1: 0.2993, loss: 1.8090
2022-07-13 19:21:04,963 - mmdet - INFO - Epoch [292][160/166]	lr: 5.000e-04, eta: 0:07:33, time: 0.336, data_time: 0.008, memory: 18400, loss_cls: 0.3335, loss_bbox: 0.9886, loss_obj: 0.1685, loss_l1: 0.3145, loss: 1.8051
2022-07-13 19:21:10,433 - mmdet - INFO - Evaluating bbox...
2022-07-13 19:21:10,511 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.683
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.875
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.859
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.680
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.697
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.731
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.731
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.731
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.738
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.738

2022-07-13 19:21:10,512 - mmdet - INFO - Exp name: yolox_l_8x8_300e_coco_airbus.py
2022-07-13 19:21:10,512 - mmdet - INFO - Epoch(val) [292][142]	bbox_mAP: 0.6830, bbox_mAP_50: 0.8750, bbox_mAP_75: 0.8590, bbox_mAP_s: -1.0000, bbox_mAP_m: 0.6800, bbox_mAP_l: 0.6970, bbox_mAP_copypaste: 0.683 0.875 0.859 -1.000 0.680 0.697
2022-07-13 19:21:16,491 - mmdet - INFO - Epoch [293][10/166]	lr: 5.000e-04, eta: 0:07:28, time: 0.596, data_time: 0.223, memory: 18400, loss_cls: 0.3481, loss_bbox: 1.0409, loss_obj: 0.2019, loss_l1: 0.3474, loss: 1.9384
2022-07-13 19:21:19,315 - mmdet - INFO - Epoch [293][20/166]	lr: 5.000e-04, eta: 0:07:24, time: 0.282, data_time: 0.008, memory: 18400, loss_cls: 0.3309, loss_bbox: 0.9753, loss_obj: 0.1624, loss_l1: 0.2977, loss: 1.7664
2022-07-13 19:21:23,173 - mmdet - INFO - Epoch [293][30/166]	lr: 5.000e-04, eta: 0:07:21, time: 0.386, data_time: 0.008, memory: 18400, loss_cls: 0.3177, loss_bbox: 0.9205, loss_obj: 0.1445, loss_l1: 0.3207, loss: 1.7033
2022-07-13 19:21:27,548 - mmdet - INFO - Epoch [293][40/166]	lr: 5.000e-04, eta: 0:07:19, time: 0.437, data_time: 0.008, memory: 18400, loss_cls: 0.3220, loss_bbox: 0.9330, loss_obj: 0.1621, loss_l1: 0.3021, loss: 1.7192
2022-07-13 19:21:30,575 - mmdet - INFO - Epoch [293][50/166]	lr: 5.000e-04, eta: 0:07:15, time: 0.303, data_time: 0.008, memory: 18400, loss_cls: 0.2973, loss_bbox: 0.8390, loss_obj: 0.1925, loss_l1: 0.2700, loss: 1.5989
2022-07-13 19:21:34,741 - mmdet - INFO - Epoch [293][60/166]	lr: 5.000e-04, eta: 0:07:12, time: 0.416, data_time: 0.008, memory: 18400, loss_cls: 0.3156, loss_bbox: 0.9008, loss_obj: 0.1887, loss_l1: 0.3134, loss: 1.7184
2022-07-13 19:21:37,669 - mmdet - INFO - Epoch [293][70/166]	lr: 5.000e-04, eta: 0:07:08, time: 0.293, data_time: 0.008, memory: 18400, loss_cls: 0.3120, loss_bbox: 0.8936, loss_obj: 0.1412, loss_l1: 0.2732, loss: 1.6201
2022-07-13 19:21:39,836 - mmdet - INFO - Epoch [293][80/166]	lr: 5.000e-04, eta: 0:07:04, time: 0.217, data_time: 0.009, memory: 18400, loss_cls: 0.3345, loss_bbox: 0.9858, loss_obj: 0.2056, loss_l1: 0.2940, loss: 1.8198
2022-07-13 19:21:42,073 - mmdet - INFO - Epoch [293][90/166]	lr: 5.000e-04, eta: 0:07:00, time: 0.224, data_time: 0.008, memory: 18400, loss_cls: 0.3290, loss_bbox: 0.9583, loss_obj: 0.1936, loss_l1: 0.2714, loss: 1.7523
2022-07-13 19:21:45,023 - mmdet - INFO - Epoch [293][100/166]	lr: 5.000e-04, eta: 0:06:56, time: 0.295, data_time: 0.008, memory: 18400, loss_cls: 0.3132, loss_bbox: 0.9022, loss_obj: 0.1578, loss_l1: 0.2787, loss: 1.6519
2022-07-13 19:21:48,615 - mmdet - INFO - Epoch [293][110/166]	lr: 5.000e-04, eta: 0:06:53, time: 0.359, data_time: 0.008, memory: 18400, loss_cls: 0.3223, loss_bbox: 0.9404, loss_obj: 0.2067, loss_l1: 0.3167, loss: 1.7860
2022-07-13 19:21:51,742 - mmdet - INFO - Epoch [293][120/166]	lr: 5.000e-04, eta: 0:06:50, time: 0.313, data_time: 0.008, memory: 18400, loss_cls: 0.2951, loss_bbox: 0.8170, loss_obj: 0.1590, loss_l1: 0.2517, loss: 1.5228
2022-07-13 19:21:55,873 - mmdet - INFO - Epoch [293][130/166]	lr: 5.000e-04, eta: 0:06:47, time: 0.413, data_time: 0.008, memory: 18400, loss_cls: 0.3423, loss_bbox: 1.0127, loss_obj: 0.1886, loss_l1: 0.3412, loss: 1.8847
2022-07-13 19:22:00,711 - mmdet - INFO - Epoch [293][140/166]	lr: 5.000e-04, eta: 0:06:44, time: 0.484, data_time: 0.008, memory: 18400, loss_cls: 0.3187, loss_bbox: 0.9221, loss_obj: 0.1757, loss_l1: 0.3366, loss: 1.7532
2022-07-13 19:22:04,948 - mmdet - INFO - Epoch [293][150/166]	lr: 5.000e-04, eta: 0:06:41, time: 0.423, data_time: 0.008, memory: 18400, loss_cls: 0.3251, loss_bbox: 0.9413, loss_obj: 0.1751, loss_l1: 0.3365, loss: 1.7781
2022-07-13 19:22:07,273 - mmdet - INFO - Epoch [293][160/166]	lr: 5.000e-04, eta: 0:06:37, time: 0.233, data_time: 0.008, memory: 18400, loss_cls: 0.3470, loss_bbox: 1.0350, loss_obj: 0.2154, loss_l1: 0.3290, loss: 1.9265
2022-07-13 19:22:12,115 - mmdet - INFO - Evaluating bbox...
2022-07-13 19:22:12,189 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.684
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.876
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.860
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.681
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.697
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.732
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.732
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.732
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.740
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.738

2022-07-13 19:22:12,190 - mmdet - INFO - Exp name: yolox_l_8x8_300e_coco_airbus.py
2022-07-13 19:22:12,190 - mmdet - INFO - Epoch(val) [293][142]	bbox_mAP: 0.6840, bbox_mAP_50: 0.8760, bbox_mAP_75: 0.8600, bbox_mAP_s: -1.0000, bbox_mAP_m: 0.6810, bbox_mAP_l: 0.6970, bbox_mAP_copypaste: 0.684 0.876 0.860 -1.000 0.681 0.697
2022-07-13 19:22:17,397 - mmdet - INFO - Epoch [294][10/166]	lr: 5.000e-04, eta: 0:06:31, time: 0.519, data_time: 0.223, memory: 18400, loss_cls: 0.3428, loss_bbox: 1.0218, loss_obj: 0.1653, loss_l1: 0.3201, loss: 1.8500
2022-07-13 19:22:19,864 - mmdet - INFO - Epoch [294][20/166]	lr: 5.000e-04, eta: 0:06:28, time: 0.247, data_time: 0.008, memory: 18400, loss_cls: 0.3314, loss_bbox: 0.9674, loss_obj: 0.1694, loss_l1: 0.2788, loss: 1.7471
2022-07-13 19:22:22,566 - mmdet - INFO - Epoch [294][30/166]	lr: 5.000e-04, eta: 0:06:24, time: 0.270, data_time: 0.008, memory: 18400, loss_cls: 0.3137, loss_bbox: 0.8973, loss_obj: 0.1876, loss_l1: 0.2677, loss: 1.6663
2022-07-13 19:22:26,016 - mmdet - INFO - Epoch [294][40/166]	lr: 5.000e-04, eta: 0:06:20, time: 0.345, data_time: 0.008, memory: 18400, loss_cls: 0.3149, loss_bbox: 0.9028, loss_obj: 0.1675, loss_l1: 0.2854, loss: 1.6706
2022-07-13 19:22:29,725 - mmdet - INFO - Epoch [294][50/166]	lr: 5.000e-04, eta: 0:06:17, time: 0.371, data_time: 0.008, memory: 18400, loss_cls: 0.3176, loss_bbox: 0.9155, loss_obj: 0.1664, loss_l1: 0.3192, loss: 1.7187
2022-07-13 19:22:33,105 - mmdet - INFO - Epoch [294][60/166]	lr: 5.000e-04, eta: 0:06:14, time: 0.338, data_time: 0.008, memory: 18400, loss_cls: 0.3369, loss_bbox: 0.9908, loss_obj: 0.1916, loss_l1: 0.3284, loss: 1.8477
2022-07-13 19:22:37,099 - mmdet - INFO - Epoch [294][70/166]	lr: 5.000e-04, eta: 0:06:11, time: 0.399, data_time: 0.009, memory: 18400, loss_cls: 0.3187, loss_bbox: 0.9199, loss_obj: 0.1777, loss_l1: 0.3254, loss: 1.7417
2022-07-13 19:22:41,733 - mmdet - INFO - Epoch [294][80/166]	lr: 5.000e-04, eta: 0:06:08, time: 0.463, data_time: 0.008, memory: 18400, loss_cls: 0.3186, loss_bbox: 0.9190, loss_obj: 0.1679, loss_l1: 0.3457, loss: 1.7512
2022-07-13 19:22:46,150 - mmdet - INFO - Epoch [294][90/166]	lr: 5.000e-04, eta: 0:06:05, time: 0.442, data_time: 0.008, memory: 18400, loss_cls: 0.3416, loss_bbox: 1.0121, loss_obj: 0.1956, loss_l1: 0.3654, loss: 1.9147
2022-07-13 19:22:48,924 - mmdet - INFO - Epoch [294][100/166]	lr: 5.000e-04, eta: 0:06:01, time: 0.277, data_time: 0.008, memory: 18400, loss_cls: 0.3223, loss_bbox: 0.9324, loss_obj: 0.1901, loss_l1: 0.2722, loss: 1.7169
2022-07-13 19:22:52,108 - mmdet - INFO - Epoch [294][110/166]	lr: 5.000e-04, eta: 0:05:58, time: 0.318, data_time: 0.008, memory: 18400, loss_cls: 0.3184, loss_bbox: 0.9248, loss_obj: 0.1656, loss_l1: 0.3010, loss: 1.7097
2022-07-13 19:22:54,941 - mmdet - INFO - Epoch [294][120/166]	lr: 5.000e-04, eta: 0:05:54, time: 0.283, data_time: 0.008, memory: 18400, loss_cls: 0.3156, loss_bbox: 0.9096, loss_obj: 0.1809, loss_l1: 0.2709, loss: 1.6770
2022-07-13 19:22:57,359 - mmdet - INFO - Epoch [294][130/166]	lr: 5.000e-04, eta: 0:05:50, time: 0.242, data_time: 0.008, memory: 18400, loss_cls: 0.3289, loss_bbox: 0.9611, loss_obj: 0.1614, loss_l1: 0.2685, loss: 1.7200
2022-07-13 19:22:59,670 - mmdet - INFO - Epoch [294][140/166]	lr: 5.000e-04, eta: 0:05:46, time: 0.231, data_time: 0.008, memory: 18400, loss_cls: 0.3404, loss_bbox: 1.0016, loss_obj: 0.1978, loss_l1: 0.3019, loss: 1.8417
2022-07-13 19:23:02,027 - mmdet - INFO - Epoch [294][150/166]	lr: 5.000e-04, eta: 0:05:42, time: 0.236, data_time: 0.008, memory: 18400, loss_cls: 0.3053, loss_bbox: 0.8739, loss_obj: 0.1588, loss_l1: 0.2568, loss: 1.5948
2022-07-13 19:23:04,916 - mmdet - INFO - Epoch [294][160/166]	lr: 5.000e-04, eta: 0:05:39, time: 0.289, data_time: 0.008, memory: 18400, loss_cls: 0.3161, loss_bbox: 0.9093, loss_obj: 0.1647, loss_l1: 0.2820, loss: 1.6722
2022-07-13 19:23:09,899 - mmdet - INFO - Evaluating bbox...
2022-07-13 19:23:09,979 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.684
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.876
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.861
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.682
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.698
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.733
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.733
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.733
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.740
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.738

2022-07-13 19:23:09,980 - mmdet - INFO - Exp name: yolox_l_8x8_300e_coco_airbus.py
2022-07-13 19:23:09,980 - mmdet - INFO - Epoch(val) [294][142]	bbox_mAP: 0.6840, bbox_mAP_50: 0.8760, bbox_mAP_75: 0.8610, bbox_mAP_s: -1.0000, bbox_mAP_m: 0.6820, bbox_mAP_l: 0.6980, bbox_mAP_copypaste: 0.684 0.876 0.861 -1.000 0.682 0.698
2022-07-13 19:23:15,072 - mmdet - INFO - Epoch [295][10/166]	lr: 5.000e-04, eta: 0:05:33, time: 0.507, data_time: 0.223, memory: 18400, loss_cls: 0.3245, loss_bbox: 0.9432, loss_obj: 0.1689, loss_l1: 0.2794, loss: 1.7159
2022-07-13 19:23:17,852 - mmdet - INFO - Epoch [295][20/166]	lr: 5.000e-04, eta: 0:05:30, time: 0.278, data_time: 0.008, memory: 18400, loss_cls: 0.3066, loss_bbox: 0.8733, loss_obj: 0.1460, loss_l1: 0.2565, loss: 1.5825
2022-07-13 19:23:20,584 - mmdet - INFO - Epoch [295][30/166]	lr: 5.000e-04, eta: 0:05:26, time: 0.273, data_time: 0.008, memory: 18400, loss_cls: 0.3115, loss_bbox: 0.8955, loss_obj: 0.1314, loss_l1: 0.2778, loss: 1.6162
2022-07-13 19:23:23,757 - mmdet - INFO - Epoch [295][40/166]	lr: 5.000e-04, eta: 0:05:23, time: 0.317, data_time: 0.008, memory: 18400, loss_cls: 0.2970, loss_bbox: 0.8364, loss_obj: 0.1514, loss_l1: 0.2666, loss: 1.5514
2022-07-13 19:23:27,755 - mmdet - INFO - Epoch [295][50/166]	lr: 5.000e-04, eta: 0:05:19, time: 0.400, data_time: 0.008, memory: 18400, loss_cls: 0.3247, loss_bbox: 0.9402, loss_obj: 0.1818, loss_l1: 0.3141, loss: 1.7608
2022-07-13 19:23:31,958 - mmdet - INFO - Epoch [295][60/166]	lr: 5.000e-04, eta: 0:05:16, time: 0.420, data_time: 0.008, memory: 18400, loss_cls: 0.3286, loss_bbox: 0.9561, loss_obj: 0.1842, loss_l1: 0.3466, loss: 1.8155
2022-07-13 19:23:35,599 - mmdet - INFO - Epoch [295][70/166]	lr: 5.000e-04, eta: 0:05:13, time: 0.364, data_time: 0.008, memory: 18400, loss_cls: 0.3085, loss_bbox: 0.8863, loss_obj: 0.1403, loss_l1: 0.2970, loss: 1.6321
2022-07-13 19:23:39,339 - mmdet - INFO - Epoch [295][80/166]	lr: 5.000e-04, eta: 0:05:10, time: 0.374, data_time: 0.008, memory: 18400, loss_cls: 0.3186, loss_bbox: 0.9223, loss_obj: 0.1663, loss_l1: 0.3052, loss: 1.7123
2022-07-13 19:23:42,381 - mmdet - INFO - Epoch [295][90/166]	lr: 5.000e-04, eta: 0:05:06, time: 0.304, data_time: 0.008, memory: 18400, loss_cls: 0.3303, loss_bbox: 0.9697, loss_obj: 0.1731, loss_l1: 0.3063, loss: 1.7795
2022-07-13 19:23:45,605 - mmdet - INFO - Epoch [295][100/166]	lr: 5.000e-04, eta: 0:05:03, time: 0.322, data_time: 0.008, memory: 18400, loss_cls: 0.3166, loss_bbox: 0.9079, loss_obj: 0.1551, loss_l1: 0.2979, loss: 1.6775
2022-07-13 19:23:50,262 - mmdet - INFO - Epoch [295][110/166]	lr: 5.000e-04, eta: 0:05:00, time: 0.466, data_time: 0.008, memory: 18400, loss_cls: 0.3170, loss_bbox: 0.9133, loss_obj: 0.1668, loss_l1: 0.3431, loss: 1.7402
2022-07-13 19:23:54,701 - mmdet - INFO - Epoch [295][120/166]	lr: 5.000e-04, eta: 0:04:57, time: 0.444, data_time: 0.017, memory: 18400, loss_cls: 0.3354, loss_bbox: 0.9876, loss_obj: 0.2411, loss_l1: 0.3422, loss: 1.9062
2022-07-13 19:23:57,124 - mmdet - INFO - Epoch [295][130/166]	lr: 5.000e-04, eta: 0:04:53, time: 0.242, data_time: 0.008, memory: 18400, loss_cls: 0.3218, loss_bbox: 0.9345, loss_obj: 0.1665, loss_l1: 0.2814, loss: 1.7042
2022-07-13 19:23:59,662 - mmdet - INFO - Epoch [295][140/166]	lr: 5.000e-04, eta: 0:04:50, time: 0.254, data_time: 0.008, memory: 18400, loss_cls: 0.3422, loss_bbox: 1.0146, loss_obj: 0.1946, loss_l1: 0.3112, loss: 1.8625
2022-07-13 19:24:02,830 - mmdet - INFO - Epoch [295][150/166]	lr: 5.000e-04, eta: 0:04:46, time: 0.317, data_time: 0.008, memory: 18400, loss_cls: 0.3254, loss_bbox: 0.9452, loss_obj: 0.1674, loss_l1: 0.3032, loss: 1.7413
2022-07-13 19:24:06,884 - mmdet - INFO - Epoch [295][160/166]	lr: 5.000e-04, eta: 0:04:43, time: 0.405, data_time: 0.007, memory: 18400, loss_cls: 0.3241, loss_bbox: 0.9432, loss_obj: 0.1791, loss_l1: 0.3203, loss: 1.7668
2022-07-13 19:24:12,048 - mmdet - INFO - Evaluating bbox...
2022-07-13 19:24:12,124 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.684
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.877
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.852
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.680
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.698
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.732
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.732
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.732
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.739
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.738

2022-07-13 19:24:12,125 - mmdet - INFO - Exp name: yolox_l_8x8_300e_coco_airbus.py
2022-07-13 19:24:12,125 - mmdet - INFO - Epoch(val) [295][142]	bbox_mAP: 0.6840, bbox_mAP_50: 0.8770, bbox_mAP_75: 0.8520, bbox_mAP_s: -1.0000, bbox_mAP_m: 0.6800, bbox_mAP_l: 0.6980, bbox_mAP_copypaste: 0.684 0.877 0.852 -1.000 0.680 0.698
2022-07-13 19:24:18,734 - mmdet - INFO - Epoch [296][10/166]	lr: 5.000e-04, eta: 0:04:38, time: 0.659, data_time: 0.225, memory: 18400, loss_cls: 0.3293, loss_bbox: 0.9653, loss_obj: 0.1566, loss_l1: 0.3428, loss: 1.7940
2022-07-13 19:24:21,992 - mmdet - INFO - Epoch [296][20/166]	lr: 5.000e-04, eta: 0:04:34, time: 0.326, data_time: 0.008, memory: 18400, loss_cls: 0.3166, loss_bbox: 0.9108, loss_obj: 0.1844, loss_l1: 0.2887, loss: 1.7004
2022-07-13 19:24:26,103 - mmdet - INFO - Exp name: yolox_l_8x8_300e_coco_airbus.py
2022-07-13 19:24:26,103 - mmdet - INFO - Epoch [296][30/166]	lr: 5.000e-04, eta: 0:04:31, time: 0.411, data_time: 0.008, memory: 18400, loss_cls: 0.3052, loss_bbox: 0.8658, loss_obj: 0.1595, loss_l1: 0.3140, loss: 1.6445
2022-07-13 19:24:29,037 - mmdet - INFO - Epoch [296][40/166]	lr: 5.000e-04, eta: 0:04:28, time: 0.293, data_time: 0.008, memory: 18400, loss_cls: 0.3267, loss_bbox: 0.9593, loss_obj: 0.1773, loss_l1: 0.2968, loss: 1.7600
2022-07-13 19:24:33,149 - mmdet - INFO - Epoch [296][50/166]	lr: 5.000e-04, eta: 0:04:25, time: 0.411, data_time: 0.008, memory: 18400, loss_cls: 0.3150, loss_bbox: 0.9102, loss_obj: 0.1642, loss_l1: 0.3138, loss: 1.7032
2022-07-13 19:24:36,783 - mmdet - INFO - Epoch [296][60/166]	lr: 5.000e-04, eta: 0:04:21, time: 0.363, data_time: 0.008, memory: 18400, loss_cls: 0.3338, loss_bbox: 0.9774, loss_obj: 0.1786, loss_l1: 0.3308, loss: 1.8205
2022-07-13 19:24:39,786 - mmdet - INFO - Epoch [296][70/166]	lr: 5.000e-04, eta: 0:04:18, time: 0.300, data_time: 0.008, memory: 18400, loss_cls: 0.3127, loss_bbox: 0.9002, loss_obj: 0.1548, loss_l1: 0.2770, loss: 1.6448
2022-07-13 19:24:42,856 - mmdet - INFO - Epoch [296][80/166]	lr: 5.000e-04, eta: 0:04:14, time: 0.307, data_time: 0.008, memory: 18400, loss_cls: 0.2962, loss_bbox: 0.8330, loss_obj: 0.1137, loss_l1: 0.2609, loss: 1.5037
2022-07-13 19:24:46,878 - mmdet - INFO - Epoch [296][90/166]	lr: 5.000e-04, eta: 0:04:11, time: 0.402, data_time: 0.008, memory: 18400, loss_cls: 0.3227, loss_bbox: 0.9355, loss_obj: 0.1655, loss_l1: 0.3237, loss: 1.7475
2022-07-13 19:24:50,386 - mmdet - INFO - Epoch [296][100/166]	lr: 5.000e-04, eta: 0:04:08, time: 0.351, data_time: 0.008, memory: 18400, loss_cls: 0.3228, loss_bbox: 0.9359, loss_obj: 0.1583, loss_l1: 0.3155, loss: 1.7325
2022-07-13 19:24:53,668 - mmdet - INFO - Epoch [296][110/166]	lr: 5.000e-04, eta: 0:04:04, time: 0.328, data_time: 0.008, memory: 18400, loss_cls: 0.3174, loss_bbox: 0.9142, loss_obj: 0.2018, loss_l1: 0.2799, loss: 1.7133
2022-07-13 19:24:57,979 - mmdet - INFO - Epoch [296][120/166]	lr: 5.000e-04, eta: 0:04:01, time: 0.431, data_time: 0.008, memory: 18400, loss_cls: 0.3015, loss_bbox: 0.8501, loss_obj: 0.1699, loss_l1: 0.3040, loss: 1.6255
2022-07-13 19:25:02,767 - mmdet - INFO - Epoch [296][130/166]	lr: 5.000e-04, eta: 0:03:58, time: 0.479, data_time: 0.008, memory: 18400, loss_cls: 0.3047, loss_bbox: 0.8609, loss_obj: 0.1820, loss_l1: 0.3241, loss: 1.6718
2022-07-13 19:25:06,827 - mmdet - INFO - Epoch [296][140/166]	lr: 5.000e-04, eta: 0:03:55, time: 0.406, data_time: 0.008, memory: 18400, loss_cls: 0.3302, loss_bbox: 0.9644, loss_obj: 0.2361, loss_l1: 0.3520, loss: 1.8827
2022-07-13 19:25:11,096 - mmdet - INFO - Epoch [296][150/166]	lr: 5.000e-04, eta: 0:03:52, time: 0.427, data_time: 0.008, memory: 18400, loss_cls: 0.3130, loss_bbox: 0.9042, loss_obj: 0.1530, loss_l1: 0.3473, loss: 1.7175
2022-07-13 19:25:15,730 - mmdet - INFO - Epoch [296][160/166]	lr: 5.000e-04, eta: 0:03:48, time: 0.463, data_time: 0.008, memory: 18400, loss_cls: 0.3193, loss_bbox: 0.9173, loss_obj: 0.2076, loss_l1: 0.3358, loss: 1.7801
2022-07-13 19:25:20,481 - mmdet - INFO - Evaluating bbox...
2022-07-13 19:25:20,554 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.685
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.877
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.852
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.681
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.698
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.731
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.731
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.731
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.739
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.737

2022-07-13 19:25:20,555 - mmdet - INFO - Exp name: yolox_l_8x8_300e_coco_airbus.py
2022-07-13 19:25:20,555 - mmdet - INFO - Epoch(val) [296][142]	bbox_mAP: 0.6850, bbox_mAP_50: 0.8770, bbox_mAP_75: 0.8520, bbox_mAP_s: -1.0000, bbox_mAP_m: 0.6810, bbox_mAP_l: 0.6980, bbox_mAP_copypaste: 0.685 0.877 0.852 -1.000 0.681 0.698
2022-07-13 19:25:25,143 - mmdet - INFO - Epoch [297][10/166]	lr: 5.000e-04, eta: 0:03:43, time: 0.457, data_time: 0.223, memory: 18400, loss_cls: 0.3169, loss_bbox: 0.9134, loss_obj: 0.1701, loss_l1: 0.2648, loss: 1.6652
2022-07-13 19:25:27,936 - mmdet - INFO - Epoch [297][20/166]	lr: 5.000e-04, eta: 0:03:39, time: 0.279, data_time: 0.008, memory: 18400, loss_cls: 0.3298, loss_bbox: 0.9604, loss_obj: 0.2067, loss_l1: 0.2864, loss: 1.7834
2022-07-13 19:25:32,044 - mmdet - INFO - Epoch [297][30/166]	lr: 5.000e-04, eta: 0:03:36, time: 0.411, data_time: 0.008, memory: 18400, loss_cls: 0.3067, loss_bbox: 0.8770, loss_obj: 0.1520, loss_l1: 0.3071, loss: 1.6427
2022-07-13 19:25:35,978 - mmdet - INFO - Epoch [297][40/166]	lr: 5.000e-04, eta: 0:03:33, time: 0.393, data_time: 0.008, memory: 18400, loss_cls: 0.3229, loss_bbox: 0.9429, loss_obj: 0.1495, loss_l1: 0.3334, loss: 1.7487
2022-07-13 19:25:39,433 - mmdet - INFO - Epoch [297][50/166]	lr: 5.000e-04, eta: 0:03:29, time: 0.345, data_time: 0.008, memory: 18400, loss_cls: 0.3264, loss_bbox: 0.9526, loss_obj: 0.1486, loss_l1: 0.3028, loss: 1.7304
2022-07-13 19:25:42,440 - mmdet - INFO - Epoch [297][60/166]	lr: 5.000e-04, eta: 0:03:26, time: 0.301, data_time: 0.008, memory: 18400, loss_cls: 0.3232, loss_bbox: 0.9340, loss_obj: 0.1793, loss_l1: 0.2834, loss: 1.7198
2022-07-13 19:25:45,310 - mmdet - INFO - Epoch [297][70/166]	lr: 5.000e-04, eta: 0:03:22, time: 0.287, data_time: 0.008, memory: 18400, loss_cls: 0.3148, loss_bbox: 0.9029, loss_obj: 0.1642, loss_l1: 0.2791, loss: 1.6610
2022-07-13 19:25:49,150 - mmdet - INFO - Epoch [297][80/166]	lr: 5.000e-04, eta: 0:03:19, time: 0.384, data_time: 0.008, memory: 18400, loss_cls: 0.3156, loss_bbox: 0.9027, loss_obj: 0.1569, loss_l1: 0.3114, loss: 1.6865
2022-07-13 19:25:52,588 - mmdet - INFO - Epoch [297][90/166]	lr: 5.000e-04, eta: 0:03:15, time: 0.344, data_time: 0.008, memory: 18400, loss_cls: 0.3044, loss_bbox: 0.8634, loss_obj: 0.1429, loss_l1: 0.2681, loss: 1.5789
2022-07-13 19:25:55,299 - mmdet - INFO - Epoch [297][100/166]	lr: 5.000e-04, eta: 0:03:12, time: 0.271, data_time: 0.008, memory: 18400, loss_cls: 0.3089, loss_bbox: 0.8870, loss_obj: 0.1560, loss_l1: 0.2636, loss: 1.6156
2022-07-13 19:25:57,938 - mmdet - INFO - Epoch [297][110/166]	lr: 5.000e-04, eta: 0:03:08, time: 0.264, data_time: 0.008, memory: 18400, loss_cls: 0.3280, loss_bbox: 0.9653, loss_obj: 0.1981, loss_l1: 0.2908, loss: 1.7822
2022-07-13 19:26:00,239 - mmdet - INFO - Epoch [297][120/166]	lr: 5.000e-04, eta: 0:03:05, time: 0.230, data_time: 0.008, memory: 18400, loss_cls: 0.3224, loss_bbox: 0.9382, loss_obj: 0.1712, loss_l1: 0.2788, loss: 1.7106
2022-07-13 19:26:03,181 - mmdet - INFO - Epoch [297][130/166]	lr: 5.000e-04, eta: 0:03:01, time: 0.294, data_time: 0.008, memory: 18400, loss_cls: 0.3052, loss_bbox: 0.8616, loss_obj: 0.1542, loss_l1: 0.2579, loss: 1.5788
2022-07-13 19:26:06,799 - mmdet - INFO - Epoch [297][140/166]	lr: 5.000e-04, eta: 0:02:58, time: 0.362, data_time: 0.008, memory: 18400, loss_cls: 0.3175, loss_bbox: 0.9151, loss_obj: 0.1377, loss_l1: 0.2975, loss: 1.6679
2022-07-13 19:26:10,754 - mmdet - INFO - Epoch [297][150/166]	lr: 5.000e-04, eta: 0:02:55, time: 0.395, data_time: 0.008, memory: 18400, loss_cls: 0.3139, loss_bbox: 0.9042, loss_obj: 0.1604, loss_l1: 0.3107, loss: 1.6892
2022-07-13 19:26:14,235 - mmdet - INFO - Epoch [297][160/166]	lr: 5.000e-04, eta: 0:02:51, time: 0.348, data_time: 0.008, memory: 18400, loss_cls: 0.3100, loss_bbox: 0.8857, loss_obj: 0.2171, loss_l1: 0.2861, loss: 1.6990
2022-07-13 19:26:18,968 - mmdet - INFO - Evaluating bbox...
2022-07-13 19:26:19,038 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.686
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.878
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.853
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.683
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.698
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.731
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.731
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.731
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.740
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.736

2022-07-13 19:26:19,039 - mmdet - INFO - Exp name: yolox_l_8x8_300e_coco_airbus.py
2022-07-13 19:26:19,039 - mmdet - INFO - Epoch(val) [297][142]	bbox_mAP: 0.6860, bbox_mAP_50: 0.8780, bbox_mAP_75: 0.8530, bbox_mAP_s: -1.0000, bbox_mAP_m: 0.6830, bbox_mAP_l: 0.6980, bbox_mAP_copypaste: 0.686 0.878 0.853 -1.000 0.683 0.698
2022-07-13 19:26:24,075 - mmdet - INFO - Epoch [298][10/166]	lr: 5.000e-04, eta: 0:02:46, time: 0.502, data_time: 0.222, memory: 18400, loss_cls: 0.2947, loss_bbox: 0.8293, loss_obj: 0.1379, loss_l1: 0.2548, loss: 1.5168
2022-07-13 19:26:26,990 - mmdet - INFO - Epoch [298][20/166]	lr: 5.000e-04, eta: 0:02:42, time: 0.291, data_time: 0.008, memory: 18400, loss_cls: 0.3032, loss_bbox: 0.8647, loss_obj: 0.1177, loss_l1: 0.2633, loss: 1.5489
2022-07-13 19:26:29,955 - mmdet - INFO - Epoch [298][30/166]	lr: 5.000e-04, eta: 0:02:39, time: 0.297, data_time: 0.008, memory: 18400, loss_cls: 0.3019, loss_bbox: 0.8633, loss_obj: 0.1452, loss_l1: 0.2810, loss: 1.5914
2022-07-13 19:26:32,186 - mmdet - INFO - Epoch [298][40/166]	lr: 5.000e-04, eta: 0:02:35, time: 0.223, data_time: 0.008, memory: 18400, loss_cls: 0.3342, loss_bbox: 0.9782, loss_obj: 0.1824, loss_l1: 0.2782, loss: 1.7731
2022-07-13 19:26:34,920 - mmdet - INFO - Epoch [298][50/166]	lr: 5.000e-04, eta: 0:02:32, time: 0.273, data_time: 0.008, memory: 18400, loss_cls: 0.3064, loss_bbox: 0.8725, loss_obj: 0.1603, loss_l1: 0.2646, loss: 1.6038
2022-07-13 19:26:37,368 - mmdet - INFO - Epoch [298][60/166]	lr: 5.000e-04, eta: 0:02:28, time: 0.245, data_time: 0.008, memory: 18400, loss_cls: 0.3030, loss_bbox: 0.8557, loss_obj: 0.1483, loss_l1: 0.2585, loss: 1.5655
2022-07-13 19:26:40,559 - mmdet - INFO - Epoch [298][70/166]	lr: 5.000e-04, eta: 0:02:25, time: 0.319, data_time: 0.007, memory: 18400, loss_cls: 0.3275, loss_bbox: 0.9601, loss_obj: 0.1439, loss_l1: 0.2903, loss: 1.7219
2022-07-13 19:26:43,855 - mmdet - INFO - Epoch [298][80/166]	lr: 5.000e-04, eta: 0:02:21, time: 0.330, data_time: 0.008, memory: 18400, loss_cls: 0.3119, loss_bbox: 0.8922, loss_obj: 0.1391, loss_l1: 0.2948, loss: 1.6380
2022-07-13 19:26:47,296 - mmdet - INFO - Epoch [298][90/166]	lr: 5.000e-04, eta: 0:02:18, time: 0.344, data_time: 0.008, memory: 18400, loss_cls: 0.3199, loss_bbox: 0.9193, loss_obj: 0.1708, loss_l1: 0.2895, loss: 1.6995
2022-07-13 19:26:49,724 - mmdet - INFO - Epoch [298][100/166]	lr: 5.000e-04, eta: 0:02:14, time: 0.243, data_time: 0.007, memory: 18400, loss_cls: 0.3261, loss_bbox: 0.9568, loss_obj: 0.1919, loss_l1: 0.2921, loss: 1.7669
2022-07-13 19:26:53,588 - mmdet - INFO - Epoch [298][110/166]	lr: 5.000e-04, eta: 0:02:11, time: 0.386, data_time: 0.008, memory: 18400, loss_cls: 0.3094, loss_bbox: 0.8816, loss_obj: 0.1712, loss_l1: 0.3023, loss: 1.6644
2022-07-13 19:26:57,538 - mmdet - INFO - Epoch [298][120/166]	lr: 5.000e-04, eta: 0:02:08, time: 0.395, data_time: 0.008, memory: 18400, loss_cls: 0.3158, loss_bbox: 0.9058, loss_obj: 0.1772, loss_l1: 0.3139, loss: 1.7127
2022-07-13 19:27:00,608 - mmdet - INFO - Epoch [298][130/166]	lr: 5.000e-04, eta: 0:02:04, time: 0.307, data_time: 0.007, memory: 18400, loss_cls: 0.3208, loss_bbox: 0.9285, loss_obj: 0.1819, loss_l1: 0.2944, loss: 1.7257
2022-07-13 19:27:05,190 - mmdet - INFO - Epoch [298][140/166]	lr: 5.000e-04, eta: 0:02:01, time: 0.458, data_time: 0.008, memory: 18400, loss_cls: 0.3168, loss_bbox: 0.9161, loss_obj: 0.1478, loss_l1: 0.3469, loss: 1.7276
2022-07-13 19:27:09,333 - mmdet - INFO - Epoch [298][150/166]	lr: 5.000e-04, eta: 0:01:58, time: 0.414, data_time: 0.008, memory: 18400, loss_cls: 0.3276, loss_bbox: 0.9584, loss_obj: 0.1791, loss_l1: 0.3284, loss: 1.7935
2022-07-13 19:27:13,327 - mmdet - INFO - Epoch [298][160/166]	lr: 5.000e-04, eta: 0:01:54, time: 0.399, data_time: 0.007, memory: 18400, loss_cls: 0.3141, loss_bbox: 0.8995, loss_obj: 0.1715, loss_l1: 0.3260, loss: 1.7111
2022-07-13 19:27:18,128 - mmdet - INFO - Evaluating bbox...
2022-07-13 19:27:18,197 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.687
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.878
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.853
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.684
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.699
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.732
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.732
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.732
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.740
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.738

2022-07-13 19:27:18,198 - mmdet - INFO - Exp name: yolox_l_8x8_300e_coco_airbus.py
2022-07-13 19:27:18,198 - mmdet - INFO - Epoch(val) [298][142]	bbox_mAP: 0.6870, bbox_mAP_50: 0.8780, bbox_mAP_75: 0.8530, bbox_mAP_s: -1.0000, bbox_mAP_m: 0.6840, bbox_mAP_l: 0.6990, bbox_mAP_copypaste: 0.687 0.878 0.853 -1.000 0.684 0.699
2022-07-13 19:27:23,548 - mmdet - INFO - Epoch [299][10/166]	lr: 5.000e-04, eta: 0:01:49, time: 0.533, data_time: 0.223, memory: 18400, loss_cls: 0.3065, loss_bbox: 0.8756, loss_obj: 0.1342, loss_l1: 0.2890, loss: 1.6053
2022-07-13 19:27:27,636 - mmdet - INFO - Epoch [299][20/166]	lr: 5.000e-04, eta: 0:01:46, time: 0.409, data_time: 0.008, memory: 18400, loss_cls: 0.3013, loss_bbox: 0.8499, loss_obj: 0.1308, loss_l1: 0.3141, loss: 1.5961
2022-07-13 19:27:31,284 - mmdet - INFO - Epoch [299][30/166]	lr: 5.000e-04, eta: 0:01:42, time: 0.365, data_time: 0.008, memory: 18400, loss_cls: 0.3001, loss_bbox: 0.8449, loss_obj: 0.1533, loss_l1: 0.2934, loss: 1.5916
2022-07-13 19:27:35,217 - mmdet - INFO - Epoch [299][40/166]	lr: 5.000e-04, eta: 0:01:39, time: 0.393, data_time: 0.007, memory: 18400, loss_cls: 0.3204, loss_bbox: 0.9360, loss_obj: 0.1528, loss_l1: 0.3302, loss: 1.7394
2022-07-13 19:27:38,589 - mmdet - INFO - Epoch [299][50/166]	lr: 5.000e-04, eta: 0:01:35, time: 0.337, data_time: 0.008, memory: 18400, loss_cls: 0.3097, loss_bbox: 0.8879, loss_obj: 0.1585, loss_l1: 0.2991, loss: 1.6552
2022-07-13 19:27:42,919 - mmdet - INFO - Epoch [299][60/166]	lr: 5.000e-04, eta: 0:01:32, time: 0.433, data_time: 0.008, memory: 18400, loss_cls: 0.3259, loss_bbox: 0.9475, loss_obj: 0.1934, loss_l1: 0.3373, loss: 1.8041
2022-07-13 19:27:46,272 - mmdet - INFO - Epoch [299][70/166]	lr: 5.000e-04, eta: 0:01:29, time: 0.335, data_time: 0.007, memory: 18400, loss_cls: 0.3075, loss_bbox: 0.8751, loss_obj: 0.1357, loss_l1: 0.2956, loss: 1.6139
2022-07-13 19:27:49,842 - mmdet - INFO - Epoch [299][80/166]	lr: 5.000e-04, eta: 0:01:25, time: 0.357, data_time: 0.008, memory: 18400, loss_cls: 0.3148, loss_bbox: 0.9084, loss_obj: 0.1535, loss_l1: 0.2914, loss: 1.6681
2022-07-13 19:27:52,716 - mmdet - INFO - Epoch [299][90/166]	lr: 5.000e-04, eta: 0:01:22, time: 0.287, data_time: 0.008, memory: 18400, loss_cls: 0.3242, loss_bbox: 0.9401, loss_obj: 0.1541, loss_l1: 0.2917, loss: 1.7100
2022-07-13 19:27:56,226 - mmdet - INFO - Epoch [299][100/166]	lr: 5.000e-04, eta: 0:01:19, time: 0.351, data_time: 0.007, memory: 18400, loss_cls: 0.3085, loss_bbox: 0.8834, loss_obj: 0.1497, loss_l1: 0.3015, loss: 1.6432
2022-07-13 19:27:58,690 - mmdet - INFO - Epoch [299][110/166]	lr: 5.000e-04, eta: 0:01:15, time: 0.246, data_time: 0.008, memory: 18400, loss_cls: 0.3194, loss_bbox: 0.9196, loss_obj: 0.1675, loss_l1: 0.2953, loss: 1.7018
2022-07-13 19:28:02,181 - mmdet - INFO - Epoch [299][120/166]	lr: 5.000e-04, eta: 0:01:12, time: 0.349, data_time: 0.008, memory: 18400, loss_cls: 0.3247, loss_bbox: 0.9394, loss_obj: 0.1943, loss_l1: 0.3098, loss: 1.7682
2022-07-13 19:28:06,469 - mmdet - INFO - Epoch [299][130/166]	lr: 5.000e-04, eta: 0:01:08, time: 0.429, data_time: 0.008, memory: 18400, loss_cls: 0.3235, loss_bbox: 0.9420, loss_obj: 0.1571, loss_l1: 0.3235, loss: 1.7460
2022-07-13 19:28:09,168 - mmdet - INFO - Epoch [299][140/166]	lr: 5.000e-04, eta: 0:01:05, time: 0.270, data_time: 0.008, memory: 18400, loss_cls: 0.3135, loss_bbox: 0.8998, loss_obj: 0.1858, loss_l1: 0.2866, loss: 1.6857
2022-07-13 19:28:12,853 - mmdet - INFO - Epoch [299][150/166]	lr: 5.000e-04, eta: 0:01:01, time: 0.369, data_time: 0.008, memory: 18400, loss_cls: 0.3077, loss_bbox: 0.8721, loss_obj: 0.1565, loss_l1: 0.2879, loss: 1.6243
2022-07-13 19:28:15,478 - mmdet - INFO - Epoch [299][160/166]	lr: 5.000e-04, eta: 0:00:58, time: 0.262, data_time: 0.007, memory: 18400, loss_cls: 0.3299, loss_bbox: 0.9612, loss_obj: 0.1775, loss_l1: 0.2908, loss: 1.7593
2022-07-13 19:28:19,912 - mmdet - INFO - Evaluating bbox...
2022-07-13 19:28:19,982 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.687
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.879
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.853
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.683
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.698
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.731
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.731
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.731
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.739
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.737

2022-07-13 19:28:19,983 - mmdet - INFO - Exp name: yolox_l_8x8_300e_coco_airbus.py
2022-07-13 19:28:19,983 - mmdet - INFO - Epoch(val) [299][142]	bbox_mAP: 0.6870, bbox_mAP_50: 0.8790, bbox_mAP_75: 0.8530, bbox_mAP_s: -1.0000, bbox_mAP_m: 0.6830, bbox_mAP_l: 0.6980, bbox_mAP_copypaste: 0.687 0.879 0.853 -1.000 0.683 0.698
2022-07-13 19:28:24,800 - mmdet - INFO - Epoch [300][10/166]	lr: 5.000e-04, eta: 0:00:53, time: 0.480, data_time: 0.223, memory: 18400, loss_cls: 0.3059, loss_bbox: 0.8699, loss_obj: 0.1633, loss_l1: 0.2825, loss: 1.6216
2022-07-13 19:28:27,858 - mmdet - INFO - Epoch [300][20/166]	lr: 5.000e-04, eta: 0:00:49, time: 0.306, data_time: 0.008, memory: 18400, loss_cls: 0.3076, loss_bbox: 0.8801, loss_obj: 0.1469, loss_l1: 0.2757, loss: 1.6104
2022-07-13 19:28:31,238 - mmdet - INFO - Epoch [300][30/166]	lr: 5.000e-04, eta: 0:00:46, time: 0.338, data_time: 0.008, memory: 18400, loss_cls: 0.3056, loss_bbox: 0.8688, loss_obj: 0.1408, loss_l1: 0.2769, loss: 1.5921
2022-07-13 19:28:35,181 - mmdet - INFO - Epoch [300][40/166]	lr: 5.000e-04, eta: 0:00:42, time: 0.394, data_time: 0.008, memory: 18400, loss_cls: 0.3020, loss_bbox: 0.8494, loss_obj: 0.1364, loss_l1: 0.2854, loss: 1.5732
2022-07-13 19:28:38,788 - mmdet - INFO - Epoch [300][50/166]	lr: 5.000e-04, eta: 0:00:39, time: 0.361, data_time: 0.008, memory: 18400, loss_cls: 0.2928, loss_bbox: 0.8219, loss_obj: 0.1264, loss_l1: 0.2799, loss: 1.5210
2022-07-13 19:28:42,447 - mmdet - INFO - Epoch [300][60/166]	lr: 5.000e-04, eta: 0:00:36, time: 0.366, data_time: 0.008, memory: 18400, loss_cls: 0.3272, loss_bbox: 0.9654, loss_obj: 0.1772, loss_l1: 0.3161, loss: 1.7859
2022-07-13 19:28:46,600 - mmdet - INFO - Epoch [300][70/166]	lr: 5.000e-04, eta: 0:00:32, time: 0.415, data_time: 0.007, memory: 18400, loss_cls: 0.3033, loss_bbox: 0.8562, loss_obj: 0.1412, loss_l1: 0.2917, loss: 1.5924
2022-07-13 19:28:49,848 - mmdet - INFO - Epoch [300][80/166]	lr: 5.000e-04, eta: 0:00:29, time: 0.325, data_time: 0.008, memory: 18400, loss_cls: 0.3259, loss_bbox: 0.9470, loss_obj: 0.1943, loss_l1: 0.3123, loss: 1.7795
2022-07-13 19:28:52,275 - mmdet - INFO - Epoch [300][90/166]	lr: 5.000e-04, eta: 0:00:25, time: 0.243, data_time: 0.008, memory: 18400, loss_cls: 0.3105, loss_bbox: 0.8869, loss_obj: 0.1730, loss_l1: 0.2773, loss: 1.6477
2022-07-13 19:28:55,486 - mmdet - INFO - Epoch [300][100/166]	lr: 5.000e-04, eta: 0:00:22, time: 0.321, data_time: 0.008, memory: 18400, loss_cls: 0.3051, loss_bbox: 0.8628, loss_obj: 0.1383, loss_l1: 0.2807, loss: 1.5870
2022-07-13 19:28:59,157 - mmdet - INFO - Epoch [300][110/166]	lr: 5.000e-04, eta: 0:00:19, time: 0.367, data_time: 0.008, memory: 18400, loss_cls: 0.3077, loss_bbox: 0.8778, loss_obj: 0.1525, loss_l1: 0.2849, loss: 1.6228
2022-07-13 19:29:02,505 - mmdet - INFO - Epoch [300][120/166]	lr: 5.000e-04, eta: 0:00:15, time: 0.335, data_time: 0.008, memory: 18400, loss_cls: 0.3194, loss_bbox: 0.9261, loss_obj: 0.1243, loss_l1: 0.2829, loss: 1.6527
2022-07-13 19:29:05,446 - mmdet - INFO - Epoch [300][130/166]	lr: 5.000e-04, eta: 0:00:12, time: 0.294, data_time: 0.008, memory: 18400, loss_cls: 0.3057, loss_bbox: 0.8672, loss_obj: 0.1601, loss_l1: 0.2750, loss: 1.6081
2022-07-13 19:29:09,128 - mmdet - INFO - Epoch [300][140/166]	lr: 5.000e-04, eta: 0:00:08, time: 0.368, data_time: 0.008, memory: 18400, loss_cls: 0.3139, loss_bbox: 0.9078, loss_obj: 0.1458, loss_l1: 0.3227, loss: 1.6901
2022-07-13 19:29:13,034 - mmdet - INFO - Epoch [300][150/166]	lr: 5.000e-04, eta: 0:00:05, time: 0.391, data_time: 0.008, memory: 18400, loss_cls: 0.3183, loss_bbox: 0.9153, loss_obj: 0.1524, loss_l1: 0.3112, loss: 1.6971
2022-07-13 19:29:16,408 - mmdet - INFO - Epoch [300][160/166]	lr: 5.000e-04, eta: 0:00:02, time: 0.337, data_time: 0.008, memory: 18400, loss_cls: 0.3081, loss_bbox: 0.8750, loss_obj: 0.1596, loss_l1: 0.2937, loss: 1.6364
2022-07-13 19:29:19,014 - mmdet - INFO - Saving checkpoint at 300 epochs
2022-07-13 19:29:23,208 - mmdet - INFO - Evaluating bbox...
2022-07-13 19:29:23,276 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.687
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.879
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.853
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.683
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.698
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.732
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.732
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.732
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.740
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.737

2022-07-13 19:29:23,277 - mmdet - INFO - Exp name: yolox_l_8x8_300e_coco_airbus.py
2022-07-13 19:29:23,277 - mmdet - INFO - Epoch(val) [300][142]	bbox_mAP: 0.6870, bbox_mAP_50: 0.8790, bbox_mAP_75: 0.8530, bbox_mAP_s: -1.0000, bbox_mAP_m: 0.6830, bbox_mAP_l: 0.6980, bbox_mAP_copypaste: 0.687 0.879 0.853 -1.000 0.683 0.698
